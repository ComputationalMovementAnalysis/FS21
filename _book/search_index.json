[
["index.html", "GEO880: Patterns and Trends in Environmental Data 1 Introduction Chapter", " GEO880: Patterns and Trends in Environmental Data Patrick Laube and Nils Ratnaweera 1 Introduction Chapter Introduce some basic concepts RStudio Tidyverse Rstudio Server / Rstudio Connect Links to GIS Ressources GIT / CMAtools "],
["lesson-1.html", "2 Lesson 1 2.1 Leaning outcomes 2.2 Prerequisites 2.3 Tasks 2.4 Solutions (RCode)", " 2 Lesson 1 For our practical R course building-up skills for analyzing movement data in the software environment R, you’ll be using data from the ZHAW project “Prävention von Wildschweinschäden in der Landwirtschaft”. The project investigates the spatiotemporal movement patterns of wild boar (Sus scrofa) in agricultural landscapes. For more information you can ask Beni Sigrist, one of the course participants involved in this project. We will study the trajectories of these wild boar, practicing the most basic analysis tasks of Computational Movement Analysis (CMA). Lesson 1 (L1) covers the necessary steps for getting ready in R and some basic concepts for setting up a well-structured R project. The lesson introduces how additional packages that provide useful functions are made available and how temporal data is handled. The lesson concludes with the creation of your first map featuring movement data. Please note we are given this data under the condition of signing a non-disclosure agreement. Why? This is data coming out of an ongoing research project. Capturing wild living animals and then equipping them with GPS collars is a very labor and cost intensive form of research. Consequently, data resulting such campaigns is a very valuable asset that must be protected. 2.1 Leaning outcomes You learn how to structure an R project. You can read movement data from a .csv-file into a data.frame and into a sf object. You can produce simple maps of your trajectory data using ggplot2, leaflet, plotly and tmap 2.2 Prerequisites Readings Skills from “R for Data Science” (Wickam, 2017): RS1.1 Preface (16p, ix-xxiv) RS1.2 Chap2 Workflow basics (3p, 37-39) RS1.3 Chap4 Workflow scripts (3p, 77-79) RS1.4 Chap6 workflow projects (6p, 111-116) RS1.5 Chap8 Data Import with readr (21p) RS1.6 Chap13 Date and Times with lubridate (18p, 237-256) 2.3 Tasks 2.3.1 Task 1: Prepare project Create a new RStudio Project. As recommended in Wickam, remove the option “Restore .RData into workspace at startup” and “save workspace to .RData on exit” to “Never”. Create a new R-File and divide it into the sections neccessary in a classical Data Science Workflow. “Sections” can be created within RStudio by adding Comments (#) with at least 4 Trailing dashes (-), equal signs (=), or pound signs (#) (see below). Sections allow code folding (try click on the small triangle next to the line number) and provides and navigation (try the shortcut: Shift+Alt+J). In the first section (loading environment / libraries), add the code to install and load the package “tidyverse”. Once you’ve installed the package, you can uncomment the corresponding line of code, because you will not need to execute this line in your next R Session. 2.3.2 Task 2: Import data In section “data import”, import the file wildschwein.csv. For everyone working on the RStudio Server, this data is saved in a Folder named “Geodata” one level above your home folder. You will have to move “up” one or two levels from your project folder using the syntax and then into the correct folder using the syntax &quot;../../Geodata/&quot;(for two levels) or &quot;../Geodata/&quot; (for one level). Note: If your are using a graphical tool to import your code, make sure you save the corresponding code in your R Script. This is important in regard to the reproducibility of your script and will ensure that your worflow is documented without gaps. I recommend using one of the tidyverse functions (read_*) to import your data. These functions are less error prone than the base R functions (read.*). Specifically to the wildboar data, I recomment read_delim. if you recieve warnings during import, have a look at these warnings by using the funciton problems(). Resolve these problems until import runs without warnings. Assign correct data types as neccessary and make sure the timezone is set correctly for the date/time columnm. 2.3.3 Task 3 Explore Data We will use a variaty of different plotting techniques in this course, several have emerged in recent years, each with their specific strenghts and weaknesses. While base::plot() is quick and simple, it not very scaleable with growing complexity. ggplto offers solution for most use cases and has a elegant syntax that is easy to get accustomed to. plotly() offers great interactive and linked view facilites while tmap() was designed specifically for spatial data. Get an overview of your data by creating a first “map-like” plot of your data producing a simple scatter plot with ggplot2. Assign every individual animal its own colour (using the ggplot2 argument colour). Do you spot outliers? If so, get rid of the outliers. Plot your data again, this time without outliers. Save your plot using ggsave(). Save your code in the appropirate section. Setting up a ggplot with our data is done using the command ggplot(roe_gps_all, aes(X, Y, colour = TierID)). Creating a map is done via the basic scatter plot command geom_point(), using a fixed aspect ratio of 1. 2.3.4 Task 4: Handling spatial data Till now, we’ve handled spatial data within dataframes. This works well for many tasks, but sometimes we need special spatial classes to handle our trajectories. Projecting the WGS84 (Lat/Long) coordinates into CH1903_LV95 is such a case. Some of you might know the sp packge with the classes SpatialPoints and SpatialPointsDataFrame. Just recently the new and exiting package sf, was released on CRAN. sf has some huge advantages over sp: simple featrues are essentially dataframes, which mean they interface with the tidyverse (and the dplyr SAC paradigm) are OGC (ISO 19125-1:2004) compliant and interface with GDAL, PostGIS, GeoJSON and so fourth are being rapidly implemented in visualisation tools such as ggplot2, gplotly and tmap A lot of reasons to learn sf and work with this library. The down side is however, that due to its youth not all packages have implemented sf. We have created a small package (CMAtools) to help you with such cases, so we will not have to switch back and fourth between classes during this course. Use the function st_as_sf() while correctly specifying your Lat/Long Coordinates. Set the coordinate reference system using the EPSG Code as an integer value. You can set the argument “agr” to “constant”. Save to output of this operation to a new variable wildschwein_BE_sf. Take a look at this sf object (head(), str(),View()) and try a few classical dataframe operations on it (subseting, filtering). Now transform the coordinates into CH1903_LV95 using the function st_transform(). Again, use the EPSG code as an integer. Extract the new Coorindates using st_coordinates() and attach them (cbind()) to your original dataframe. Note that st_transform() names the coordinates X and Y, but CH1903 LV03 names the Axes E and N. Rename the axes accordingly before or after attaching them to your dataframe. Keep your Long / Lat coordinates, since it is helpful to have both WGS84 and CH1903+ Coordinates stored in the dataframe: WGS84: this is our original data therefore we should not discard this information. Additionally, some visualization tools (eg. Leaflet and ggmap) need Lat/Long Coordinates CH1903+ these cartesian coordinates are helpful when calculating euclidean distances between positions (this is much more compledated with WGS84 Data) and if we use swisstopo background- and other context data 2.4 Solutions (RCode) ## Task 1 #################### # Loading enironment / libraries #### # install.packages(&quot;tidyverse&quot;) library(tidyverse) library(sf) ## Task 2 #################### # Data import #### wildschwein_BE &lt;- read_delim(&quot;../Geodata/wildschwein_BE.csv&quot;,&quot;,&quot;) ## Task 3 #################### ggplot(wildschwein_BE, aes(Lat,Long, colour = TierID)) + geom_point() + coord_fixed(1) + theme(legend.position = &quot;none&quot;) wildschwein_BE &lt;- filter(wildschwein_BE, Lat &lt; 50) ## Task 4 #################### wildschwein_BE_sf = st_as_sf(wildschwein_BE, coords = c(&quot;Long&quot;, &quot;Lat&quot;), crs = 4326, agr = &quot;constant&quot;) ## Task 4 (Continued) ######## wildschwein_BE_sf &lt;- st_transform(wildschwein_BE_sf, 2056) coordinates &lt;- st_coordinates(wildschwein_BE_sf) colnames(coordinates) &lt;- c(&quot;E&quot;,&quot;N&quot;) wildschwein_BE &lt;- cbind(wildschwein_BE,coordinates) ## NA "],
["lesson-2.html", "3 Lesson 2 3.1 Learning Outcomes 3.2 Prerequisites 3.3 Preperation 3.4 Tasks 3.5 Solutions (RCode)", " 3 Lesson 2 3.1 Learning Outcomes 3.2 Prerequisites Readings Skills from “R for Data Science” (Wickam, 2017): RS2.1 Chap3 Data Transformation with dplyr (31p, 43-76) RS2.2 Chap10 Relational data with dplyr (21p, 171-193) RS2.3 Chap14 Pipes with magrittr (6p, 261-268) R2.1 Laube, P., &amp; Purves, R. S. (2011). How fast is a cow? cross‐scale analysis of movement data. Transactions in GIS, 15(3), 401-418. 3.3 Preperation Open your R Project from last week. Load all libraries and run the scrip to import and clean your data. Install and load the following additional libraries. 3.4 Tasks 3.4.1 Task 1 Depending on your knowledge of R, getting an overview of the data we imported last week might have been quite a challange. Quite surprisingly, importing, cleaning and exploring your data can be the most challanging, time consuming part of a project. RStudio and the tidyverse offer many extremely helpful tools to make this part easier, and more fun. To get an overview of the data, use the dplyr tools group_by, summarise. Try to answer the following questions: How many individuals were tracked? How long were the individual tracked? Are there gaps? Were all individuals tracked cuncurrently or sequentially? What is the temporal sampling interval between the locations? 3.4.2 Task 2 Now that we’ve established that we have different sampling intervals, we have to segement our trajectories in such a way, that we can perform further analysis during specific sampling intervals only. If we measure speed, or turning angles, we have to be very clear on what temporal (an thus spatial) scale we are performing this analysis. We therefore have to define threshold to group segments with a similar sampling interval. Explore the dataset in more detail (e.g. using histograms at different scales), and choose reasonable threshold values to group the trajectories into different sampling intervals. Use the function cut() to apply the thresholds on the column timelag. Note: It might make more sense to choose narrow group intervals at smaller timelags and wider groups intervals at higher timelags. The function cut splits a vector into segements according to the values specified in breaks = . The default lables can be a bit puzzling at first, but ( and ] are a standard form of notating intervals in mathematics. 3.4.3 Task 3 Now that we’ve gotten the nifty job of specifying our intervals out of the way, let’s get to a more fun part and calculate the speed of the animals movements. If you’re working with dplyr, you can add samplingInt to group_by() (in addition to TierID) and so make sure your’re not calculating speed across different sampling intervals. You can use the function euclid() from the CMAtools package to calculate euclidean distances between subsequent rows. Use ?euclid to see what the function expects and returns. use lead(E,1) to address the the row n+1 make sure you’re clear in what unit you are measuring speed. Meters per second is a SI base unit, but might be unhandy for the speeds travelled by wild boar. 3.4.4 Task 4 Measuring speed between subsequent samples is great, but especially for short sampling intervals they can be missleading due to measurment error. It might be desireble to “smoothen” these erros using a moving window function. The zoo package offeres a variaty of moving window functions (roll*). Use roll_mean to smoothen the calculated speed. Familiarise yourself with this function by working on some dummy data, for example: example &lt;- rnorm(10) rollmean(example,k = 3,fill = NA,align = &quot;left&quot;) rollmean(example,k = 4,fill = NA,align = &quot;left&quot;) Visualize the output from your moving windows and compare different window sizes (k = ). 3.4.5 Task 5 You’ve read Laube &amp; Purves (2011) about segementing trajectories Let’s use this same method on our wild boar data. Laube &amp; Purves (2011) define “static” fixes as “those whose average Euclidean distance to other fixes inside a temporal window v is less than some threshold d”. We can nicely implement this method with the tools we’ve used so far. Let me illustrate on some dummy data: set.seed(10) X = cumsum(rnorm(20)) Y = cumsum(rnorm(20)) plot(X,Y, type = &quot;l&quot;) We’ll assume they have a sampling interval of 5 minutes. If we take a temporal window of 20 minutes, that would mean we include 5 fixes into the calculation. We need to calculate the following Eucledian distances (pos representing a X,Y-position): pos[n-2] to pos[n] pos[n-1] to pos[n] pos[n] to pos[n+1] pos[n] to pos[n+2] We can use the function euclid() to calculate the distances and dplyr functions lead()/lag() to create the necessary offsets. nMinus2 &lt;- euclid(lag(X, 2),lag(Y, 2),X,Y) # distance to pos. -10 minutes nMinus1 &lt;- euclid(lag(X, 1),lag(Y, 1),X,Y) # distance to pos. -5 minutes nPlus1 &lt;- euclid(X,Y,lead(X, 1),lead(Y, 1)) # distance to pos +5 mintues nPlus2 &lt;- euclid(X,Y,lead(X, 2),lead(Y, 2)) # distance to pos +10 minutes We can now bind all these values to a matrix: distances &lt;- cbind(nMinus2,nMinus1,nPlus1,nPlus2) distances ## nMinus2 nMinus1 nPlus1 nPlus2 ## [1,] NA NA 2.1930407 3.255812 ## [2,] NA 2.1930407 1.5283951 3.418902 ## [3,] 3.255812 1.5283951 2.2021404 3.397941 ## [4,] 3.418902 2.2021404 1.2990315 1.776001 ## [5,] 3.397941 1.2990315 0.5399653 1.340062 ## [6,] 1.776001 0.5399653 1.3900290 2.214298 ## [7,] 1.340062 1.3900290 0.9449451 2.215854 ## [8,] 2.214298 0.9449451 1.6298525 1.916421 ## [9,] 2.215854 1.6298525 0.3608126 2.270722 ## [10,] 1.916421 0.3608126 2.1564489 2.679915 ## [11,] 2.270722 2.1564489 0.7597903 1.030078 ## [12,] 2.679915 0.7597903 0.9974347 1.375450 ## [13,] 1.030078 0.9974347 1.0046117 2.101651 ## [14,] 1.375450 1.0046117 1.5664940 2.935460 ## [15,] 2.101651 1.5664940 1.4382922 1.378950 ## [16,] 2.935460 1.4382922 1.0212859 1.809509 ## [17,] 1.378950 1.0212859 1.7698785 2.207931 ## [18,] 1.809509 1.7698785 0.9807744 1.713668 ## [19,] 2.207931 0.9807744 0.8110503 NA ## [20,] 1.713668 0.8110503 NA NA We now need to find the mean value per row. mean() just gives us the overall mean mean(distances, na.rm = T) ## [1] 1.719808 We therefore need the function rowMeans() rowmeans &lt;- rowMeans(distances) cbind(distances,rowmeans) ## nMinus2 nMinus1 nPlus1 nPlus2 rowmeans ## [1,] NA NA 2.1930407 3.255812 NA ## [2,] NA 2.1930407 1.5283951 3.418902 NA ## [3,] 3.255812 1.5283951 2.2021404 3.397941 2.596072 ## [4,] 3.418902 2.2021404 1.2990315 1.776001 2.174019 ## [5,] 3.397941 1.2990315 0.5399653 1.340062 1.644250 ## [6,] 1.776001 0.5399653 1.3900290 2.214298 1.480073 ## [7,] 1.340062 1.3900290 0.9449451 2.215854 1.472723 ## [8,] 2.214298 0.9449451 1.6298525 1.916421 1.676379 ## [9,] 2.215854 1.6298525 0.3608126 2.270722 1.619310 ## [10,] 1.916421 0.3608126 2.1564489 2.679915 1.778399 ## [11,] 2.270722 2.1564489 0.7597903 1.030078 1.554260 ## [12,] 2.679915 0.7597903 0.9974347 1.375450 1.453147 ## [13,] 1.030078 0.9974347 1.0046117 2.101651 1.283444 ## [14,] 1.375450 1.0046117 1.5664940 2.935460 1.720504 ## [15,] 2.101651 1.5664940 1.4382922 1.378950 1.621347 ## [16,] 2.935460 1.4382922 1.0212859 1.809509 1.801137 ## [17,] 1.378950 1.0212859 1.7698785 2.207931 1.594511 ## [18,] 1.809509 1.7698785 0.9807744 1.713668 1.568457 ## [19,] 2.207931 0.9807744 0.8110503 NA NA ## [20,] 1.713668 0.8110503 NA NA NA You can now combine these steps to calculate the values for the wild boars. If you do it with dplyr::summarise(), you can make sure that the dataframe is grouped per animal and sampling interval via group_by(). 3.5 Solutions (RCode) ## install.packages(&quot;devtools&quot;) ## install.packages(&quot;zoo&quot;) ## ## devtools::install_git(&quot;https://github.engineering.zhaw.ch/PatternsTrendsEnvironmentalData/CMAtools.git&quot;) library(CMAtools) library(zoo) ## Task 1 #################### ggplot(wildschwein_BE, aes(DatetimeUTC,TierID)) + geom_line() wildschwein_BE &lt;- wildschwein_BE %&gt;% group_by(TierID) %&gt;% mutate( timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = &quot;mins&quot;)) ) ggplot(wildschwein_BE, aes(timelag)) + geom_histogram(binwidth = 50) ggplot(wildschwein_BE, aes(timelag)) + geom_histogram(binwidth = 1) + lims(x = c(0,100)) + scale_y_log10() wildschwein_BE[1:50,] %&gt;% ggplot(aes(DatetimeUTC,timelag)) + geom_line() + geom_point() ## Task 2 #################### ggplot(wildschwein_BE, aes(timelag)) + geom_histogram(binwidth = 0.1) + scale_x_continuous(breaks = seq(0,400,20),limits = c(0,400)) + # scale_x_continuous(breaks = seq(0,50,1),limits = c(0,50)) + scale_y_log10() wildschwein_BE &lt;- wildschwein_BE %&gt;% group_by(TierID) %&gt;% mutate( samplingInt = cut(timelag,breaks = c(0,5,seq(10,195,15))) ) wildschwein_BE %&gt;% group_by(samplingInt) %&gt;% summarise( n = n() ) %&gt;% ggplot(aes(samplingInt,n)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_y_log10() ## Task 3 #################### wildschwein_BE &lt;- wildschwein_BE %&gt;% group_by(TierID,samplingInt) %&gt;% mutate( steplength = euclid(lead(E),lead(N),E,N), speed = steplength/timelag ) ggplot(wildschwein_BE, aes(samplingInt,speed,group = samplingInt)) + geom_boxplot() + scale_y_continuous(limits = c(0,100)) example &lt;- rnorm(10) rollmean(example,k = 3,fill = NA,align = &quot;left&quot;) rollmean(example,k = 4,fill = NA,align = &quot;left&quot;) ## Task 4 #################### wildschwein_BE &lt;- wildschwein_BE %&gt;% group_by(TierID) %&gt;% mutate( speed2 = rollmean(speed,3,NA,align = &quot;left&quot;), speed3 = rollmean(speed,5,NA,align = &quot;left&quot;), speed4 = rollmean(speed,10,NA,align = &quot;left&quot;) ) wildschwein_BE[1:30,] %&gt;% gather(key,val,c(speed,speed2,speed3,speed4)) %&gt;% ggplot(aes(DatetimeUTC,val,colour = key,group = key)) + geom_point() + geom_line() ## Task 5 #################### wildschwein_BE &lt;- wildschwein_BE %&gt;% group_by(TierID) %&gt;% mutate( stepMean = rowMeans( cbind( euclid(lag(E, 2),lag(N, 2),E,N), euclid(lag(E, 1),lag(N, 1),E,N), euclid(E,N,lead(E, 1),lead(N, 1)), euclid(E,N,lead(E, 2),lead(N, 2)) ) ) ) ## NA "]
]
