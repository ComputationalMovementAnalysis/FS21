\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Patterns and Trends in Environmental Data},
            pdfauthor={Patrick Laube and Nils Ratnaweera},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Patterns and Trends in Environmental Data}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \subtitle{Master ENR, Spring Semester 2020}
  \author{Patrick Laube and Nils Ratnaweera}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{11 February, 2020}


\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{introduction-chapter}{%
\chapter*{Introduction Chapter}\label{introduction-chapter}}
\addcontentsline{toc}{chapter}{Introduction Chapter}

For our practical \texttt{R} course building-up skills for analyzing movement data in the software environment \texttt{R}, you'll be using data from the ZHAW project \href{https://www.zhaw.ch/de/lsfm/institute-zentren/iunr/integrative-oekologie/wildtiermanagement/referenzprojekte/}{``Prävention von Wildschweinschäden in der Landwirtschaft''}.

The project investigates the spatiotemporal movement patterns of wild boar (\emph{Sus scrofa}) in agricultural landscapes. We will study the trajectories of these wild boar, practicing the most basic analysis tasks of Computational Movement Analysis (CMA).

\textbf{Please note:} we are given application data from an ongoing research project. Capturing wild living animals and then equipping them with GPS collars is a very labor and cost intensive form of research. Consequently, data resulting such campaigns is a very valuable asset that must be protected. So, please do not pass on this data, for any use beyond this module contact Patrick Laube or the data owner Stefan Suter (\href{mailto:suts@zhaw.ch}{\nolinkurl{suts@zhaw.ch}}).

\hypertarget{exercise-1}{%
\chapter{Exercise 1}\label{exercise-1}}

Exercise 1 covers the necessary steps for getting ready in \texttt{R} and some basic concepts for setting up a well-structured \texttt{R} project. The lesson introduces how additional packages that provide useful functions for data science are made available and how spatial data is handled. The exercise concludes with the creation of your first map featuring movement data.

\hypertarget{leaning-outcomes}{%
\section{Leaning outcomes}\label{leaning-outcomes}}

\begin{itemize}
\tightlist
\item
  You learn how to structure an \texttt{R} project.
\item
  You can read movement data from a .csv-file into a \texttt{data.frame}
\item
  You can convert spatial point data from a \texttt{data.frame} to a spatial object \texttt{sf}
\item
  You can perform basic spatial operations on spatial objects in \texttt{R}
\item
  You can produce simple maps of your spatial data using \texttt{ggplot2}
\item
  You can produce simple maps of your spatial data using \texttt{tmap}
\end{itemize}

\hypertarget{prerequisites}{%
\section{Prerequisites}\label{prerequisites}}

Readings Skills from ``R for Data Science'' (Wickham and Grolemund \protect\hyperlink{ref-wickham2017}{2017}):

\begin{itemize}
\tightlist
\item
  RS1.1 Preface (16p, ix-xxiv)
\item
  RS1.2 Chap2 Workflow basics (3p, 37-39)
\item
  RS1.3 Chap4 Workflow scripts (3p, 77-79)
\item
  RS1.4 Chap6 workflow projects (6p, 111-116)
\item
  RS1.5 Chap8 Data Import with \texttt{readr} (21p)
\item
  RS1.6 Chap13 Date and Times with \texttt{lubridate} (18p, 237-256)
\end{itemize}

\hypertarget{preperation}{%
\section{Preperation}\label{preperation}}

If you haven't already, install the packages \texttt{tidyverse}, and \texttt{devtools} (using \texttt{install.packages()}). Additionally, install the packages \texttt{sf}, \texttt{raster} and \texttt{ggspatial}. \textbf{Restart your \texttt{R} session after installing all these packages.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"tidyverse"}\NormalTok{)}
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"sf"}\NormalTok{)}
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"raster"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{tasks-and-inputs}{%
\section{Tasks and inputs}\label{tasks-and-inputs}}

\hypertarget{task-1-initialize-project}{%
\subsection{Task 1: Initialize project}\label{task-1-initialize-project}}

Create a new \emph{RStudio Project}. As recommended in Wickham and Grolemund (\protect\hyperlink{ref-wickham2017}{2017}), remove the option ``\emph{Restore .RData into workspace at startup}'' and set the option ``\emph{save workspace to .RData on exit}'' to ``\emph{Never}''.

Create a new .R (or .Rmd) File and divide it into the sections necessary in a classical Data Science Workflow. In .R Files, ``Sections'' can be created within RStudio by adding Comments (\texttt{\#}) with at least 4 trailing dashes, equal, or pound signs ( \texttt{-}, \texttt{=},\texttt{\#}). In .Rmd Files, their are created with leading pound signs (\texttt{\#}).

Sections allow code folding (try clicking on the small triangle next to the line number) and facilitate navigation (try the shortcut: \texttt{Shift}+\texttt{Alt}+\texttt{J}). We recommend following sections:

\begin{itemize}
\tightlist
\item
  Loading environment / libraries
\item
  Data import
\item
  Data cleansing
\item
  Data analysis and visualization
\end{itemize}

\hypertarget{task-2-import-data}{%
\subsection{Task 2: Import data}\label{task-2-import-data}}

In section ``data import'', import the file \texttt{wildschwein\_BE.csv}. Obtain this file from moodle.

Note:

\begin{itemize}
\tightlist
\item
  If your are using \href{https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio}{a graphical tool} to import your code, make sure you save the corresponding code in your R Script. This is important in regard to the reproducibility of your script and will ensure that your workflow is documented without gaps. We'd rather recommend to move away from using graphical tools and focus on using code.
\item
  We recommend using one of the \texttt{tidyverse} functions from the \texttt{readr} package to import your data (they all begin with "\texttt{read\_*}, note the underscore). These functions are less error prone than the base \texttt{R} functions (\texttt{read.*}). Specifically for the wild boar data, we recommend \texttt{read\_delim()}.
\item
  If you use \texttt{read\_delim()} and receive warnings during import, have a look at these warnings by using the function \texttt{problems()}. Resolve these problems until import runs without warnings.
\item
  Assign correct data types as necessary and make sure the time zone is set correctly for the date/time column.
\item
  For everyone working on the RStudio Server: You will first need to upload this data to the server using the ``\emph{upload}''-button in the ``\emph{Files}'' tab.
\end{itemize}

\hypertarget{task-3-explore-data}{%
\subsection{Task 3: Explore Data}\label{task-3-explore-data}}

We will use a range of different visualization tools (i.e.~R-packages) in this course. Several packages techniques have emerged in recent years, each with their specific strengths and weaknesses. While \texttt{base::plot()}is quick and simple, it not very scalable with growing complexity. \texttt{ggplot2} offers solutions for most use cases and has an elegant, consistent syntax that is easy to get accustomed to. We will get to know other techniques later in the course.

Get an overview of your data by creating a first ``map-like'' plot of your data producing a simple scatter plot with \texttt{ggplot2}.
Setting up a \texttt{ggplot} with our data is done using the command \texttt{ggplot(wildschwein\_BE,\ aes(Long,\ Lat,\ colour\ =\ TierID))}. Creating a map is done via the basic scatter plot command \texttt{geom\_point()}.
Assigning every individual its own colour is done using the \texttt{ggplot} argument \texttt{colour\ =}.

Save your code in the appropriate section.

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-11-1.pdf}

\hypertarget{input-handling-spatial-data}{%
\subsection{Input: Handling spatial data}\label{input-handling-spatial-data}}

Until now, we've stored our location data within data frames as Lat/Long columns. This works well for many tasks, but sometimes we need special \emph{spatial} classes to handle our trajectories. We will get to know such cases in our next tasks, but first we need to convert our \texttt{data.frame} into a spatial object.
Some of you might be familiar with the \texttt{sp} package with the classes \texttt{SpatialPoints}, \texttt{SpatialPointsDataFrame} and so on. These packages are mostly replaced by the fairly new package \texttt{sf}. This packages has some huge advantages over \texttt{sp}:

\begin{itemize}
\tightlist
\item
  simple features are essentially data frames with minor extensions and thus are easily integratable in standard workflows
\item
  they are programmed to cleanly interface with the \texttt{tidyverse} methods (specifically \texttt{dplyr}'s \texttt{mutate} and \texttt{summarise})
\item
  comply with the common Open Geospatial Consortium (OGC) standards (ISO 19125-1:2004) and interface with other important spatial tools such as GDAL, PostGIS, GeoJSON and so fourth
\item
  are being rapidly implemented in visualisation tools such as \texttt{ggplot2}, \texttt{plotly} and \texttt{tmap}
\end{itemize}

We will largely rely on \texttt{sf}when working with vector data in \texttt{R}. In order to transform our \texttt{data.frame} into an sf object, we need to use the function \texttt{st\_as\_sf()} while specifying the columns storing the coordinates and the coordinate reference system\footnote{At this point, we assume you know what a Coordinate Reference Systems is. Check out \href{https://earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/}{this link} if this is not the case.}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(sf)}

\NormalTok{wildschwein_BE_sf <-}\StringTok{ }\KeywordTok{st_as_sf}\NormalTok{(wildschwein_BE, }\DataTypeTok{coords =} \KeywordTok{c}\NormalTok{(}\StringTok{"Long"}\NormalTok{, }\StringTok{"Lat"}\NormalTok{), }\DataTypeTok{crs =} \DecValTok{4326}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Notice how \texttt{st\_as\_sf} takes the EPSG code for the \texttt{crs\ =} argument. This is so much easier and more elegant than using \texttt{PROJ.4} or \texttt{WKT}. You can find a lot of useful information on Coordinate Reference Systems (including EPSG Codes , etc.) under \href{http://spatialreference.org/ref/epsg/2056/}{spatialreference.org} or \url{http://epsg.io}.

Let's compare our original \texttt{data.frame} with this new \texttt{sf} object:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wildschwein_BE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 51,246 x 6
##    TierID TierName CollarID DatetimeUTC           Lat  Long
##    <chr>  <chr>       <dbl> <dttm>              <dbl> <dbl>
##  1 002A   Sabi        12275 2014-08-22 21:00:12  47.0  7.05
##  2 002A   Sabi        12275 2014-08-22 21:15:16  47.0  7.05
##  3 002A   Sabi        12275 2014-08-22 21:30:43  47.0  7.05
##  4 002A   Sabi        12275 2014-08-22 21:46:07  47.0  7.05
##  5 002A   Sabi        12275 2014-08-22 22:00:22  47.0  7.05
##  6 002A   Sabi        12275 2014-08-22 22:15:10  47.0  7.05
##  7 002A   Sabi        12275 2014-08-22 22:30:13  47.0  7.05
##  8 002A   Sabi        12275 2014-08-22 22:45:11  47.0  7.05
##  9 002A   Sabi        12275 2014-08-22 23:00:27  47.0  7.05
## 10 002A   Sabi        12275 2014-08-22 23:15:41  47.0  7.05
## # ... with 51,236 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wildschwein_BE_sf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Simple feature collection with 51246 features and 4 fields
## geometry type:  POINT
## dimension:      XY
## bbox:           xmin: 7.019889 ymin: 46.97125 xmax: 7.112075 ymax: 47.01882
## epsg (SRID):    4326
## proj4string:    +proj=longlat +datum=WGS84 +no_defs
## # A tibble: 51,246 x 5
##    TierID TierName CollarID DatetimeUTC                    geometry
##    <chr>  <chr>       <dbl> <dttm>                      <POINT [°]>
##  1 002A   Sabi        12275 2014-08-22 21:00:12 (7.049618 46.99317)
##  2 002A   Sabi        12275 2014-08-22 21:15:16 (7.049509 46.99416)
##  3 002A   Sabi        12275 2014-08-22 21:30:43 (7.049406 46.99383)
##  4 002A   Sabi        12275 2014-08-22 21:46:07 (7.049217 46.99375)
##  5 002A   Sabi        12275 2014-08-22 22:00:22 (7.049359 46.99375)
##  6 002A   Sabi        12275 2014-08-22 22:15:10 (7.049363 46.99382)
##  7 002A   Sabi        12275 2014-08-22 22:30:13 (7.049326 46.99387)
##  8 002A   Sabi        12275 2014-08-22 22:45:11 (7.049237 46.99395)
##  9 002A   Sabi        12275 2014-08-22 23:00:27 (7.048383 46.99481)
## 10 002A   Sabi        12275 2014-08-22 23:15:41 (7.049396 46.99373)
## # ... with 51,236 more rows
\end{verbatim}

As you can see, \texttt{st\_as\_sf()} has added some metadata to our dataframe (\texttt{geometry\ type}, \texttt{dimension}, \texttt{bbox}, \texttt{epsg} and \texttt{proj4string}) and replaced the columns \texttt{Lat} and \texttt{Long} with a column named \texttt{geometry}. Other than that, the new \texttt{sf} object is very similar to our original dataframe. In fact, \texttt{sf} objects \emph{are} essentially \texttt{dataframes}, just ask \texttt{R}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{is.data.frame}\NormalTok{(wildschwein_BE_sf)}
\CommentTok{## [1] TRUE}
\end{Highlighting}
\end{Shaded}

All operations we know from handling \texttt{data.frames} can be used on the \texttt{sf} object. Try some out!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# subset rows}
\NormalTok{wildschwein_BE_sf[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{,]}
\NormalTok{wildschwein_BE_sf[wildschwein_BE_sf}\OperatorTok{$}\NormalTok{TierName }\OperatorTok{==}\StringTok{ "Sabi"}\NormalTok{,]}

\CommentTok{# subset colums}
\NormalTok{wildschwein_BE_sf[,}\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Instead of keeping the same data twice (once as a \texttt{data.frame}, and once as an \texttt{sf} object), we will overwrite the \texttt{data.frame} and continue working with the \texttt{sf} object from now on. This saves some memory space in \texttt{R} and avoids confusion.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wildschwein_BE =}\StringTok{ }\KeywordTok{st_as_sf}\NormalTok{(wildschwein_BE, }\DataTypeTok{coords =} \KeywordTok{c}\NormalTok{(}\StringTok{"Long"}\NormalTok{, }\StringTok{"Lat"}\NormalTok{), }\DataTypeTok{crs =} \DecValTok{4326}\NormalTok{)}

\KeywordTok{rm}\NormalTok{(wildschwein_BE_sf) }\CommentTok{# we can remove this sf object, since it just eats up our memory}
\end{Highlighting}
\end{Shaded}

\hypertarget{task-4-project-data-from-wgs84}{%
\subsection{Task 4: Project data from WGS84}\label{task-4-project-data-from-wgs84}}

So what can we do with our new \texttt{sf} object that we couldn't before? One example is projecting the WGS84 (\texttt{Lat}/\texttt{Long}) coordinates into the new Swiss CRS \texttt{CH1903+\ LV95}\footnote{As we've mentioned in the first Input, you can look up the EPSG codes under \href{http://spatialreference.org/ref/epsg/2056/}{spatialreference.org} or \url{http://epsg.io}. For information specific to Switzerland, check the \href{https://www.swisstopo.admin.ch/en/knowledge-facts/surveying-geodesy/reference-systems.html}{swisstopo website}}. Do this by using the function \texttt{st\_transform}. By the way, do you notice a pattern here? The package \texttt{sf} names most functions for spatial operations with the prefix \texttt{st\_*}, just as in PostGIS.

Here's the resulting \texttt{sf} object from the operation:

\begin{verbatim}
## Simple feature collection with 51246 features and 4 fields
## geometry type:  POINT
## dimension:      XY
## bbox:           xmin: 2568153 ymin: 1202306 xmax: 2575154 ymax: 1207609
## epsg (SRID):    2056
## proj4string:    +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs
## # A tibble: 51,246 x 5
##    TierID TierName CollarID DatetimeUTC                  geometry
##    <chr>  <chr>       <dbl> <dttm>                    <POINT [m]>
##  1 002A   Sabi        12275 2014-08-22 21:00:12 (2570409 1204752)
##  2 002A   Sabi        12275 2014-08-22 21:15:16 (2570402 1204863)
##  3 002A   Sabi        12275 2014-08-22 21:30:43 (2570394 1204826)
##  4 002A   Sabi        12275 2014-08-22 21:46:07 (2570379 1204817)
##  5 002A   Sabi        12275 2014-08-22 22:00:22 (2570390 1204818)
##  6 002A   Sabi        12275 2014-08-22 22:15:10 (2570390 1204825)
##  7 002A   Sabi        12275 2014-08-22 22:30:13 (2570387 1204831)
##  8 002A   Sabi        12275 2014-08-22 22:45:11 (2570381 1204840)
##  9 002A   Sabi        12275 2014-08-22 23:00:27 (2570316 1204935)
## 10 002A   Sabi        12275 2014-08-22 23:15:41 (2570393 1204815)
## # ... with 51,236 more rows
\end{verbatim}

\hypertarget{input-calculate-convex-hull}{%
\subsection{Input: Calculate Convex Hull}\label{input-calculate-convex-hull}}

Transforming from one Coordinate Reference System to another was one operation where we needed an object with a spatial nature. In this way, we were able to use an off the shelf function to project the coordinates from one CRS to another. In our next example, we again rely on a spatial function: We want to calculate a \href{https://en.wikipedia.org/wiki/Convex_hull}{convex hull} per Wild boar. And guess what the function for calculating a convex hull is called in \texttt{sf}? If you guessed \texttt{st\_convex\_hull()}, you were right!

By default \texttt{st\_convex\_hull()} calculates the convex hull \emph{per feature}, i.e. \emph{per point} in our dataset. This of course makes little sense. In order to calculate the convex hull per animal, we need to convert our point- to multipoint-features where each feature contains all positions of one animal. This is achieved in two steps:

First: add a grouping variable to the \texttt{sf} object. Note the new grouping variable in the metadata of the \texttt{sf} object. Other than that, \texttt{group\_by} has no effect on our \texttt{sf} object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wildschwein_BE_grouped <-}\StringTok{ }\KeywordTok{group_by}\NormalTok{(wildschwein_BE,TierID)}

\NormalTok{wildschwein_BE_grouped}
\CommentTok{## Simple feature collection with 51246 features and 4 fields}
\CommentTok{## geometry type:  POINT}
\CommentTok{## dimension:      XY}
\CommentTok{## bbox:           xmin: 2568153 ymin: 1202306 xmax: 2575154 ymax: 1207609}
\CommentTok{## epsg (SRID):    2056}
\CommentTok{## proj4string:    +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs}
\CommentTok{## # A tibble: 51,246 x 5}
\CommentTok{## # Groups:   TierID [3]}
\CommentTok{##    TierID TierName CollarID DatetimeUTC                  geometry}
\CommentTok{##    <chr>  <chr>       <dbl> <dttm>                    <POINT [m]>}
\CommentTok{##  1 002A   Sabi        12275 2014-08-22 21:00:12 (2570409 1204752)}
\CommentTok{##  2 002A   Sabi        12275 2014-08-22 21:15:16 (2570402 1204863)}
\CommentTok{##  3 002A   Sabi        12275 2014-08-22 21:30:43 (2570394 1204826)}
\CommentTok{##  4 002A   Sabi        12275 2014-08-22 21:46:07 (2570379 1204817)}
\CommentTok{##  5 002A   Sabi        12275 2014-08-22 22:00:22 (2570390 1204818)}
\CommentTok{##  6 002A   Sabi        12275 2014-08-22 22:15:10 (2570390 1204825)}
\CommentTok{##  7 002A   Sabi        12275 2014-08-22 22:30:13 (2570387 1204831)}
\CommentTok{##  8 002A   Sabi        12275 2014-08-22 22:45:11 (2570381 1204840)}
\CommentTok{##  9 002A   Sabi        12275 2014-08-22 23:00:27 (2570316 1204935)}
\CommentTok{## 10 002A   Sabi        12275 2014-08-22 23:15:41 (2570393 1204815)}
\CommentTok{## # ... with 51,236 more rows}
\end{Highlighting}
\end{Shaded}

Second: use \texttt{summarise()} to ``dissolve'' all points into a mulipoint object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wildschwein_BE_smry <-}\StringTok{ }\KeywordTok{summarise}\NormalTok{(wildschwein_BE_grouped)}

\NormalTok{wildschwein_BE_smry}
\CommentTok{## Simple feature collection with 3 features and 1 field}
\CommentTok{## geometry type:  MULTIPOINT}
\CommentTok{## dimension:      XY}
\CommentTok{## bbox:           xmin: 2568153 ymin: 1202306 xmax: 2575154 ymax: 1207609}
\CommentTok{## epsg (SRID):    2056}
\CommentTok{## proj4string:    +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs}
\CommentTok{## # A tibble: 3 x 2}
\CommentTok{##   TierID                                                           geometry}
\CommentTok{## * <chr>                                                    <MULTIPOINT [m]>}
\CommentTok{## 1 002A   (2568903 1206200, 2568925 1206207, 2568980 1206197, 2569024 12063~}
\CommentTok{## 2 016A   (2569231 1205823, 2569245 1205925, 2569247 1206027, 2569251 12058~}
\CommentTok{## 3 018A   (2568153 1205611, 2568155 1205613, 2568161 1205624, 2568162 12056~}
\end{Highlighting}
\end{Shaded}

Now we can run \texttt{st\_convex\_hull} on the new \texttt{sf} object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mcp <-}\StringTok{ }\KeywordTok{st_convex_hull}\NormalTok{(wildschwein_BE_smry)}
\end{Highlighting}
\end{Shaded}

\hypertarget{task-5-ploting-spatial-objects}{%
\subsection{Task 5: Ploting spatial objects}\label{task-5-ploting-spatial-objects}}

Using base plot to visualize \texttt{sf} objects is easy enough, just try the following code.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(mcp)}
\end{Highlighting}
\end{Shaded}

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-30-1.pdf}

But since we use \texttt{ggplot} extensively, try and plot the object \texttt{mcp} with \texttt{ggplot}. Hint: Use the layer \texttt{geom\_sf()} to add an \texttt{sf} object.

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-31-1.pdf}

Note: \texttt{ggplot} refuses to use our specified CRS, so we need to force this by specifying \texttt{datum\ =} in \texttt{coord\_sf()}. Try it out.

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-32-1.pdf}

\hypertarget{input-importing-raster-data}{%
\subsection{Input: Importing raster data}\label{input-importing-raster-data}}

In the next task, we would like to add a background map to our \texttt{mcp} object. To do this, we have to the raster data into \texttt{R} first. For this, we use the package \texttt{raster} with the function \texttt{brick}.

\begin{Shaded}
\begin{Highlighting}[]

\KeywordTok{library}\NormalTok{(raster)}

\NormalTok{pk100_BE <-}\StringTok{ }\KeywordTok{brick}\NormalTok{(}\StringTok{"00_Rawdata/pk100_BE_2056.tif"}\NormalTok{)}

\NormalTok{pk100_BE}
\CommentTok{## class      : RasterBrick }
\CommentTok{## dimensions : 1821, 2321, 4226541, 4  (nrow, ncol, ncell, nlayers)}
\CommentTok{## resolution : 5, 5  (x, y)}
\CommentTok{## extent     : 2567000, 2578605, 1199996, 1209101  (xmin, xmax, ymin, ymax)}
\CommentTok{## crs        : +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs }
\CommentTok{## source     : /home/staff/bako/unix/Lehre/Master/Pattends_and_Trends/Unterrichtsunterlagen_FS2020/00_Rawdata/pk100_BE_2056.tif }
\CommentTok{## names      : pk100_BE_2056.1, pk100_BE_2056.2, pk100_BE_2056.3, pk100_BE_2056.4 }
\CommentTok{## min values :               0,               0,               0,               0 }
\CommentTok{## max values :             255,             255,             255,             255}
\end{Highlighting}
\end{Shaded}

\texttt{pk100\_BE\_2056.tif} is a three layered geotiff File. The above console output shows some metadata including the resolution, extent and the names of our layers (\texttt{pk100\_BE\_2056.1}, \texttt{pk100\_BE\_2056.2}etc). For some reason, \texttt{RasterBrick} imported a fourth layer (\texttt{pk100\_BE\_2056.4}). \texttt{plot()} shows that the fourth layer is empty. We will remove this layer using \texttt{subset()}.

\begin{Shaded}
\begin{Highlighting}[]

\KeywordTok{plot}\NormalTok{(pk100_BE)}
\end{Highlighting}
\end{Shaded}

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-36-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{pk100_BE <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(pk100_BE,}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{)}

\KeywordTok{plot}\NormalTok{(pk100_BE)}
\end{Highlighting}
\end{Shaded}

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-36-2.pdf}

\hypertarget{task-6-adding-a-background-map}{%
\subsection{Task 6: Adding a background map}\label{task-6-adding-a-background-map}}

There are multiple ways to add a background map in \texttt{ggplot}, many require additional packages. This is a good opportunity to get to know a completely different package for creating maps: \texttt{tmap} (``thematic map''). This package was developed with a syntax very similar to \texttt{ggplot2}, which makes it easy to learn.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tmap)}


\KeywordTok{tm_shape}\NormalTok{(pk100_BE) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{tm_rgb}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-39-1.pdf}

As you can see, plotting layers in \texttt{tmap} is combined with the \texttt{+} sign, just as in \texttt{ggplot2}. In \texttt{tmap} however, each layer consists of two objects: a \texttt{tm\_shape()} in which the data is called, and a \texttt{tm\_*} object in which we define how the data is visualized (\texttt{tm\_rgb()} states that it is plotted as an RGB Raster Layer). Add the object \texttt{mcp} to the plot in this manner. Read \href{https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html}{the vignette} if you are having trouble.

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-40-1.pdf}

\hypertarget{task-7-create-an-interactive-map}{%
\subsection{Task 7: Create an interactive map}\label{task-7-create-an-interactive-map}}

Rerun the \texttt{tmap()...} command from the previous task, but switch the plotting mode to ``view''" (\texttt{tmap\_mode("view")}) beforehand. Omit the raster layer (\texttt{pk100\_BE}), you won't be needing it.

\hypertarget{exercise-3}{%
\chapter{Exercise 3}\label{exercise-3}}

\hypertarget{learning-outcomes}{%
\section{Learning Outcomes}\label{learning-outcomes}}

\begin{itemize}
\tightlist
\item
  You are able to segment a trajectory, e.g.~using the approach proposed in Laube and Purves (\protect\hyperlink{ref-laube2011}{2011})
\item
  You are able to compute the similarity between given trajectories using the package \texttt{SimilarityMeasures.}
\item
  You acquire further useful data processing skills.
\end{itemize}

\hypertarget{prerequisites-1}{%
\section{Prerequisites}\label{prerequisites-1}}

Readings Skills from ``R for Data Science'' (Wickham and Grolemund \protect\hyperlink{ref-wickham2017}{2017}):

\begin{itemize}
\tightlist
\item
  RS3.1 Chap1 Data visualization with \texttt{ggplot2} (31, 3-35)
\item
  RS3.2 Chap5 Exploratory Data Analysis (28p, 81.109)
\end{itemize}

Readings Theory:

Alan Both (\protect\hyperlink{ref-both2018}{2018}) A Comparative Analysis of Trajectory Similarity Measures: Recommendations for Selection and Use, excerpt from an unpublished manuscript, confidential.

\hypertarget{preperation-1}{%
\section{Preperation}\label{preperation-1}}

Install the following libraries:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"SimilarityMeasures"}\NormalTok{)}

\CommentTok{# The following packages are for optional tasks:}
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"plotly"}\NormalTok{)}

\CommentTok{# You don't really need the following packages, }
\CommentTok{# we just use them in our figures}
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"ggrepel"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Open your R Project from last week. Either run your own script from last week or the following lines to transform the data into the form we need for today's exercise.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(sf)}

\CommentTok{# Import as dataframe}
\NormalTok{wildschwein_BE <-}\StringTok{ }\KeywordTok{read_delim}\NormalTok{(}\StringTok{"00_Rawdata/wildschwein_BE.csv"}\NormalTok{,}\StringTok{","}\NormalTok{)}

\CommentTok{# Convert to sf-object}
\NormalTok{wildschwein_BE =}\StringTok{ }\KeywordTok{st_as_sf}\NormalTok{(wildschwein_BE, }\DataTypeTok{coords =} \KeywordTok{c}\NormalTok{(}\StringTok{"Long"}\NormalTok{, }\StringTok{"Lat"}\NormalTok{), }\DataTypeTok{crs =} \DecValTok{4326}\NormalTok{,}\DataTypeTok{remove =} \OtherTok{FALSE}\NormalTok{)}

\CommentTok{# transform to CH1903 LV95}
\NormalTok{wildschwein_BE <-}\StringTok{ }\KeywordTok{st_transform}\NormalTok{(wildschwein_BE, }\DecValTok{2056}\NormalTok{)}

\CommentTok{# Add geometry as E/N integer Columns}
\NormalTok{wildschwein_BE <-}\StringTok{ }\KeywordTok{st_coordinates}\NormalTok{(wildschwein_BE) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{cbind}\NormalTok{(wildschwein_BE,.) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{E =}\NormalTok{ X) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{N =}\NormalTok{ Y)}

\CommentTok{# Compute timelag, steplength and speed}
\NormalTok{wildschwein_BE <-}\StringTok{ }\NormalTok{wildschwein_BE }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(TierID) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{timelag =} \KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{difftime}\NormalTok{(}\KeywordTok{lead}\NormalTok{(DatetimeUTC),DatetimeUTC,}\DataTypeTok{units =} \StringTok{"secs"}\NormalTok{)),}
    \DataTypeTok{steplength =} \KeywordTok{sqrt}\NormalTok{((E}\OperatorTok{-}\KeywordTok{lead}\NormalTok{(E))}\OperatorTok{^}\DecValTok{2}\OperatorTok{+}\NormalTok{(N}\OperatorTok{-}\KeywordTok{lead}\NormalTok{(N))}\OperatorTok{^}\DecValTok{2}\NormalTok{),}
    \DataTypeTok{speed =}\NormalTok{ steplength}\OperatorTok{/}\NormalTok{timelag}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{tasks-and-inputs-1}{%
\section{Tasks and Inputs}\label{tasks-and-inputs-1}}

\hypertarget{input-segmentation-as-in-laube-and-purves-2011}{%
\subsection{Input: Segmentation as in Laube and Purves (2011)}\label{input-segmentation-as-in-laube-and-purves-2011}}

You've read Laube and Purves (\protect\hyperlink{ref-laube2011}{2011}) about segmenting trajectories. In the paper, the authors define ``\emph{static}'' fixes as ``\emph{those whose average Euclidean distance to other fixes inside a temporal window v is less than some threshold d}'', as illustrated in the following figure:

\includegraphics{02_Images/laube_2011.jpg}

The above image from Laube and Purves (\protect\hyperlink{ref-laube2011}{2011}) visualizes the following steps:

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Temporal representation of constant sample interval with associated temporal window v for three exemplary points;
\item
  Measurement of average distance in temporal window v to sample points in spatial representation;
\item
  Removal of all points where average distance is less than a given threshold, i.e.~removal of static points; and
\item
  Removal of subtrajectories with less than a threshold temporal length.
\end{enumerate}

We will implement this method on the following dummy data. Once you've grasped the idea on this simple data, you will implement it for the wild boar data in task 1.

Note: I use \texttt{tibble()} instead of \texttt{data.frame()}. The two functions are very similar, this is just a matter of preference.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\NormalTok{n =}\StringTok{ }\DecValTok{20}
\NormalTok{df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}\DataTypeTok{X =} \KeywordTok{cumsum}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(n)), }\DataTypeTok{Y =} \KeywordTok{cumsum}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(n)))}

\KeywordTok{ggplot}\NormalTok{(df, }\KeywordTok{aes}\NormalTok{(X,Y)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_path}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_equal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-49-1.pdf}

\hypertarget{segmenting}{%
\subsubsection{Segmenting}\label{segmenting}}

The first step is calculating the distances to temporally close samples within the temporal window \emph{v}. Take the following sample data, assuming the sampling interval is 5 minutes. If we take a temporal window of 20 minutes, that would mean including 5 fixes. We need to calculate the following Euclidean distances (pos representing single location):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{pos{[}n-2}{]} to \texttt{pos{[}n{]}}
\item
  \texttt{pos{[}n-1{]}} to \texttt{pos{[}n{]}}
\item
  \texttt{pos{[}n{]}} to \texttt{pos{[}n+1{]}}
\item
  \texttt{pos{[}n{]}} to \texttt{pos{[}n+2{]}}
\end{enumerate}

Just like last week, we use the formular for calculating the Euclidean distance in in combination with \texttt{lead()} and \texttt{lag()}. For example, to create the necessary offset of n-2, we use \texttt{lag(x,\ 2)}. For each offset, we create one individual column.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{df <-}\StringTok{ }\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{nMinus2 =} \KeywordTok{sqrt}\NormalTok{((}\KeywordTok{lag}\NormalTok{(X,}\DecValTok{2}\NormalTok{)}\OperatorTok{-}\NormalTok{X)}\OperatorTok{^}\DecValTok{2}\OperatorTok{+}\NormalTok{(}\KeywordTok{lag}\NormalTok{(Y,}\DecValTok{2}\NormalTok{)}\OperatorTok{-}\NormalTok{Y)}\OperatorTok{^}\DecValTok{2}\NormalTok{),   }\CommentTok{# distance to pos -10 minutes}
    \DataTypeTok{nMinus1 =} \KeywordTok{sqrt}\NormalTok{((}\KeywordTok{lag}\NormalTok{(X,}\DecValTok{1}\NormalTok{)}\OperatorTok{-}\NormalTok{X)}\OperatorTok{^}\DecValTok{2}\OperatorTok{+}\NormalTok{(}\KeywordTok{lag}\NormalTok{(Y,}\DecValTok{1}\NormalTok{)}\OperatorTok{-}\NormalTok{Y)}\OperatorTok{^}\DecValTok{2}\NormalTok{),   }\CommentTok{# distance to pos - 5 minutes}
    \DataTypeTok{nPlus1  =} \KeywordTok{sqrt}\NormalTok{((X}\OperatorTok{-}\KeywordTok{lead}\NormalTok{(X,}\DecValTok{1}\NormalTok{))}\OperatorTok{^}\DecValTok{2}\OperatorTok{+}\NormalTok{(Y}\OperatorTok{-}\KeywordTok{lead}\NormalTok{(Y,}\DecValTok{1}\NormalTok{))}\OperatorTok{^}\DecValTok{2}\NormalTok{), }\CommentTok{# distance to pos + 5 mintues}
    \DataTypeTok{nPlus2  =} \KeywordTok{sqrt}\NormalTok{((X}\OperatorTok{-}\KeywordTok{lead}\NormalTok{(X,}\DecValTok{2}\NormalTok{))}\OperatorTok{^}\DecValTok{2}\OperatorTok{+}\NormalTok{(Y}\OperatorTok{-}\KeywordTok{lead}\NormalTok{(Y,}\DecValTok{2}\NormalTok{))}\OperatorTok{^}\DecValTok{2}\NormalTok{)  }\CommentTok{# distance to pos +10 minutes}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Now we want to calculate the mean distance of \texttt{nMinus2}, \texttt{nMinus1}, \texttt{nPlus1}, \texttt{nPlus2} for each row. The below function calculates the overall mean of all columns, which is not what we want.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{stepMean =} \KeywordTok{mean}\NormalTok{(}\KeywordTok{c}\NormalTok{(nMinus2, nMinus1,nPlus1,nPlus2), }\DataTypeTok{na.rm =}\NormalTok{ T)}
\NormalTok{  )}
\CommentTok{## # A tibble: 20 x 7}
\CommentTok{##          X       Y nMinus2 nMinus1 nPlus1 nPlus2 stepMean}
\CommentTok{##      <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>    <dbl>}
\CommentTok{##  1  0.0187  -0.596   NA     NA      2.19    3.26     1.72}
\CommentTok{##  2 -0.166   -2.78    NA      2.19   1.53    3.42     1.72}
\CommentTok{##  3 -1.54    -3.46     3.26   1.53   2.20    3.40     1.72}
\CommentTok{##  4 -2.14    -5.58     3.42   2.20   1.30    1.78     1.72}
\CommentTok{##  5 -1.84    -6.84     3.40   1.30   0.540   1.34     1.72}
\CommentTok{##  6 -1.45    -7.21     1.78   0.540  1.39    2.21     1.72}
\CommentTok{##  7 -2.66    -7.90     1.34   1.39   0.945   2.22     1.72}
\CommentTok{##  8 -3.02    -8.77     2.21   0.945  1.63    1.92     1.72}
\CommentTok{##  9 -4.65    -8.88     2.22   1.63   0.361   2.27     1.72}
\CommentTok{## 10 -4.91    -9.13     1.92   0.361  2.16    2.68     1.72}
\CommentTok{## 11 -3.80   -11.0      2.27   2.16   0.760   1.03     1.72}
\CommentTok{## 12 -3.05   -11.1      2.68   0.760  0.997   1.38     1.72}
\CommentTok{## 13 -3.29   -10.1      1.03   0.997  1.00    2.10     1.72}
\CommentTok{## 14 -2.30    -9.91     1.38   1.00   1.57    2.94     1.72}
\CommentTok{## 15 -1.56   -11.3      2.10   1.57   1.44    1.38     1.72}
\CommentTok{## 16 -1.47   -12.7      2.94   1.44   1.02    1.81     1.72}
\CommentTok{## 17 -2.42   -12.4      1.38   1.02   1.77    2.21     1.72}
\CommentTok{## 18 -2.62   -14.1      1.81   1.77   0.981   1.71     1.72}
\CommentTok{## 19 -1.69   -14.4      2.21   0.981  0.811  NA        1.72}
\CommentTok{## 20 -1.21   -15.1      1.71   0.811 NA      NA        1.72}
\end{Highlighting}
\end{Shaded}

Since we want the mean value \emph{per Row}, we have to explicitly specify this before \texttt{mutate()} with the function \texttt{rowwise()}. Note the new grouping variable \texttt{\textless{}by\ row\textgreater{}} when printing the dataframe to the console.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rowwise}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{stepMean =} \KeywordTok{mean}\NormalTok{(}\KeywordTok{c}\NormalTok{(nMinus2, nMinus1,nPlus1,nPlus2))}
\NormalTok{  )}

\NormalTok{df}
\CommentTok{## Source: local data frame [20 x 7]}
\CommentTok{## Groups: <by row>}
\CommentTok{## }
\CommentTok{## # A tibble: 20 x 7}
\CommentTok{##          X       Y nMinus2 nMinus1 nPlus1 nPlus2 stepMean}
\CommentTok{##      <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>    <dbl>}
\CommentTok{##  1  0.0187  -0.596   NA     NA      2.19    3.26    NA   }
\CommentTok{##  2 -0.166   -2.78    NA      2.19   1.53    3.42    NA   }
\CommentTok{##  3 -1.54    -3.46     3.26   1.53   2.20    3.40     2.60}
\CommentTok{##  4 -2.14    -5.58     3.42   2.20   1.30    1.78     2.17}
\CommentTok{##  5 -1.84    -6.84     3.40   1.30   0.540   1.34     1.64}
\CommentTok{##  6 -1.45    -7.21     1.78   0.540  1.39    2.21     1.48}
\CommentTok{##  7 -2.66    -7.90     1.34   1.39   0.945   2.22     1.47}
\CommentTok{##  8 -3.02    -8.77     2.21   0.945  1.63    1.92     1.68}
\CommentTok{##  9 -4.65    -8.88     2.22   1.63   0.361   2.27     1.62}
\CommentTok{## 10 -4.91    -9.13     1.92   0.361  2.16    2.68     1.78}
\CommentTok{## 11 -3.80   -11.0      2.27   2.16   0.760   1.03     1.55}
\CommentTok{## 12 -3.05   -11.1      2.68   0.760  0.997   1.38     1.45}
\CommentTok{## 13 -3.29   -10.1      1.03   0.997  1.00    2.10     1.28}
\CommentTok{## 14 -2.30    -9.91     1.38   1.00   1.57    2.94     1.72}
\CommentTok{## 15 -1.56   -11.3      2.10   1.57   1.44    1.38     1.62}
\CommentTok{## 16 -1.47   -12.7      2.94   1.44   1.02    1.81     1.80}
\CommentTok{## 17 -2.42   -12.4      1.38   1.02   1.77    2.21     1.59}
\CommentTok{## 18 -2.62   -14.1      1.81   1.77   0.981   1.71     1.57}
\CommentTok{## 19 -1.69   -14.4      2.21   0.981  0.811  NA       NA   }
\CommentTok{## 20 -1.21   -15.1      1.71   0.811 NA      NA       NA}
\end{Highlighting}
\end{Shaded}

We can now determin if an animal is moving or not by specifying a threshold on \texttt{stepMean}

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{df <-}\StringTok{ }\NormalTok{df }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{moving =}\NormalTok{ stepMean}\OperatorTok{>}\FloatTok{1.5}
\NormalTok{    )}

\NormalTok{df}
\CommentTok{## Source: local data frame [20 x 8]}
\CommentTok{## Groups: <by row>}
\CommentTok{## }
\CommentTok{## # A tibble: 20 x 8}
\CommentTok{##          X       Y nMinus2 nMinus1 nPlus1 nPlus2 stepMean moving}
\CommentTok{##      <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>    <dbl> <lgl> }
\CommentTok{##  1  0.0187  -0.596   NA     NA      2.19    3.26    NA    NA    }
\CommentTok{##  2 -0.166   -2.78    NA      2.19   1.53    3.42    NA    NA    }
\CommentTok{##  3 -1.54    -3.46     3.26   1.53   2.20    3.40     2.60 TRUE  }
\CommentTok{##  4 -2.14    -5.58     3.42   2.20   1.30    1.78     2.17 TRUE  }
\CommentTok{##  5 -1.84    -6.84     3.40   1.30   0.540   1.34     1.64 TRUE  }
\CommentTok{##  6 -1.45    -7.21     1.78   0.540  1.39    2.21     1.48 FALSE }
\CommentTok{##  7 -2.66    -7.90     1.34   1.39   0.945   2.22     1.47 FALSE }
\CommentTok{##  8 -3.02    -8.77     2.21   0.945  1.63    1.92     1.68 TRUE  }
\CommentTok{##  9 -4.65    -8.88     2.22   1.63   0.361   2.27     1.62 TRUE  }
\CommentTok{## 10 -4.91    -9.13     1.92   0.361  2.16    2.68     1.78 TRUE  }
\CommentTok{## 11 -3.80   -11.0      2.27   2.16   0.760   1.03     1.55 TRUE  }
\CommentTok{## 12 -3.05   -11.1      2.68   0.760  0.997   1.38     1.45 FALSE }
\CommentTok{## 13 -3.29   -10.1      1.03   0.997  1.00    2.10     1.28 FALSE }
\CommentTok{## 14 -2.30    -9.91     1.38   1.00   1.57    2.94     1.72 TRUE  }
\CommentTok{## 15 -1.56   -11.3      2.10   1.57   1.44    1.38     1.62 TRUE  }
\CommentTok{## 16 -1.47   -12.7      2.94   1.44   1.02    1.81     1.80 TRUE  }
\CommentTok{## 17 -2.42   -12.4      1.38   1.02   1.77    2.21     1.59 TRUE  }
\CommentTok{## 18 -2.62   -14.1      1.81   1.77   0.981   1.71     1.57 TRUE  }
\CommentTok{## 19 -1.69   -14.4      2.21   0.981  0.811  NA       NA    NA    }
\CommentTok{## 20 -1.21   -15.1      1.71   0.811 NA      NA       NA    NA}

\KeywordTok{ggplot}\NormalTok{(df, }\KeywordTok{aes}\NormalTok{(X,Y)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_path}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{colour =}\NormalTok{ moving)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_equal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-53-1.pdf}

\hypertarget{unique-ids-per-segment}{%
\subsubsection{\texorpdfstring{Unique IDs \emph{per segment}}{Unique IDs per segment}}\label{unique-ids-per-segment}}

When segmenting trajectories, we often want to compute metrics on the basis of \emph{each segment}. Within the tidyverse logic, we need a unique ID per segment that we can pass to \texttt{group\_by()}. In other words, we need a unique ID for a sequence of successive \texttt{TRUE} values. For lack of a better way, we suggest solving this problem with \texttt{cumsum()}.

\texttt{cumsum()} returns the cummulative sum of a given vector:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{one_to_ten <-}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{10}
\NormalTok{one_to_ten}
\CommentTok{##  [1]  1  2  3  4  5  6  7  8  9 10}
\KeywordTok{cumsum}\NormalTok{(one_to_ten)}
\CommentTok{##  [1]  1  3  6 10 15 21 28 36 45 55}
\end{Highlighting}
\end{Shaded}

In R, \texttt{TRUE}and \texttt{FALSE} are interprated as \texttt{1} and \texttt{0} if coerced to an integer.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.integer}\NormalTok{(}\OtherTok{TRUE}\NormalTok{)}
\CommentTok{## [1] 1}
\KeywordTok{as.integer}\NormalTok{(}\OtherTok{FALSE}\NormalTok{)}
\CommentTok{## [1] 0}

\OtherTok{TRUE}\OperatorTok{+}\OtherTok{TRUE}
\CommentTok{## [1] 2}
\end{Highlighting}
\end{Shaded}

Therefore, \texttt{cumsum()} on a boolean vector increases the count on each \texttt{TRUE} value:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{boolvec <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\OtherTok{FALSE}\NormalTok{,}\OtherTok{FALSE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{)}

\NormalTok{df_cumsum <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}\DataTypeTok{boolvec =}\NormalTok{ boolvec,}\DataTypeTok{cumsum =} \KeywordTok{cumsum}\NormalTok{(boolvec))}

\NormalTok{df_cumsum}
\CommentTok{## # A tibble: 8 x 2}
\CommentTok{##   boolvec cumsum}
\CommentTok{##   <lgl>    <int>}
\CommentTok{## 1 FALSE        0}
\CommentTok{## 2 TRUE         1}
\CommentTok{## 3 TRUE         2}
\CommentTok{## 4 TRUE         3}
\CommentTok{## 5 FALSE        3}
\CommentTok{## 6 FALSE        3}
\CommentTok{## 7 TRUE         4}
\CommentTok{## 8 TRUE         5}
\end{Highlighting}
\end{Shaded}

You might have noticed that this is pretty much exactly the opposite of what we need. We therefore have to take the inverse of the boolean vector:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{df_cumsum }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{boolvec_inverse =} \OperatorTok{!}\NormalTok{boolvec,}
    \DataTypeTok{cumsum2 =} \KeywordTok{cumsum}\NormalTok{(boolvec_inverse)}
\NormalTok{  )}
\CommentTok{## # A tibble: 8 x 4}
\CommentTok{##   boolvec cumsum boolvec_inverse cumsum2}
\CommentTok{##   <lgl>    <int> <lgl>             <int>}
\CommentTok{## 1 FALSE        0 TRUE                  1}
\CommentTok{## 2 TRUE         1 FALSE                 1}
\CommentTok{## 3 TRUE         2 FALSE                 1}
\CommentTok{## 4 TRUE         3 FALSE                 1}
\CommentTok{## 5 FALSE        3 TRUE                  2}
\CommentTok{## 6 FALSE        3 TRUE                  3}
\CommentTok{## 7 TRUE         4 FALSE                 3}
\CommentTok{## 8 TRUE         5 FALSE                 3}
\end{Highlighting}
\end{Shaded}

To simplify our workflow, we can we can take the inverse of \texttt{boolvec} \emph{within} our \texttt{cumsum()} statement and save an extra line of code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df_cumsum }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{cumsum2 =} \KeywordTok{cumsum}\NormalTok{(}\OperatorTok{!}\NormalTok{boolvec)}
\NormalTok{  )}
\CommentTok{## # A tibble: 8 x 3}
\CommentTok{##   boolvec cumsum cumsum2}
\CommentTok{##   <lgl>    <int>   <int>}
\CommentTok{## 1 FALSE        0       1}
\CommentTok{## 2 TRUE         1       1}
\CommentTok{## 3 TRUE         2       1}
\CommentTok{## 4 TRUE         3       1}
\CommentTok{## 5 FALSE        3       2}
\CommentTok{## 6 FALSE        3       3}
\CommentTok{## 7 TRUE         4       3}
\CommentTok{## 8 TRUE         5       3}
\end{Highlighting}
\end{Shaded}

\hypertarget{task-1-segmentation}{%
\subsection{Task 1: Segmentation}\label{task-1-segmentation}}

With the skills from the input above we can now implement the segmentation algorithm described in Laube and Purves (\protect\hyperlink{ref-laube2011}{2011}). The described method depends on a regular sampling interval. Therefore, take the dataset ``caro60.csv'' from task 3 of last week (available on moodle). Import it as a dataframe, we don't need an \texttt{sf}-object to for today's tasks.

Next, we have to have to define our \emph{temporal window v} (Laube and Purves \protect\hyperlink{ref-laube2011}{2011}). To keep things simple, I would suggest a window of n +/- 2 minutes. With a sampling interval of around 1 minute, this corresponds to a window size of n +/- 2 positions.

\hypertarget{task-2-specify-and-apply-threshold-d}{%
\subsection{\texorpdfstring{Task 2: Specify and apply threshold \emph{d}}{Task 2: Specify and apply threshold d}}\label{task-2-specify-and-apply-threshold-d}}

After calculating the Euclidean distances to positions within the temporal window \emph{v} in task 1, you can explore these values (we stored them in the column \texttt{stepMean}) using summary statistics (histograms, boxplot, \texttt{summary()}): This way we can define a reasonable threshold value to differentiate between ``stops'' and ``moves''. There is no ``correct'' way of doing this, specifying a threshold always depends on data as well as the question that needs to be answered. In this exercise, find a threshold that matches your intuition.

Store the new information (boolean to differentiate between stops (\texttt{TRUE}) and moves (\texttt{FALSE})) in a new column named \texttt{moving}.

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
##  0.8109  2.2397  3.3496  5.0371  5.8618 24.2903       4
\end{verbatim}

\begin{figure}
\centering
\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-64-1.pdf}
\caption{\label{fig:unnamed-chunk-64}My summary statistics shows a mean of 5, the histogram shows that this might be a reasonable threshold.}
\end{figure}

\hypertarget{task-3-visualize-segmented-trajectories}{%
\subsection{Task 3: Visualize segmented trajectories}\label{task-3-visualize-segmented-trajectories}}

Now visualize the segmented trajectory spatially. Just like last week, you can use ggplot with \texttt{geom\_path()}, \texttt{geom\_point()} and \texttt{coord\_equal()}. Assign \texttt{colour\ =\ moving} within \texttt{aes()} to distinguish between segments \emph{with} ``movement'' and \emph{without}.

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-68-1.pdf}

Tip: if you want to get a \texttt{ggplot()} with Zoom capability, just load the library \texttt{plotly} and wrap the \texttt{ggplot()} function with \texttt{ggplotly()}

\begin{figure}
\centering
\includegraphics{_book/patterns-and-trends_files/figure-html/unnamed-chunk-68-1.png}
\caption{The interactive map/plot is only available in the online version of this document.}
\end{figure}

\hypertarget{task-4-segment-based-analysis}{%
\subsection{Task 4: Segment-based analysis}\label{task-4-segment-based-analysis}}

In applying Laube and Purves (\protect\hyperlink{ref-laube2011}{2011}), we've come as far as steps (b)/(c) in \href{02_Images/laube_2011.jpg}{Figure 1}. In order to complete step (d) (\emph{Removal of subtrajectories with less than a threshold temporal length}), we have to calculate each segment's temporal duration.

In order to do this, we need a \emph{unique} name for each segment that we can use as a grouping variable. This is where the \texttt{cumsum()} approach which we introduced in the input comes useful. Complete the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Filter the data by removing all rows where \texttt{moving} equals to \texttt{NA} (typically these are the the first and last 2 rows).
\item
  Get a unique ID per segment and using the \texttt{cumsum()} approach we introduced in the input. Store this ID in a new column \texttt{segment\_ID}
\item
  Filter the data to remove all rows where the animal is not moving
\item
  Group by the column \texttt{segment\_ID} to calculate the temporal length of each segment with \texttt{mutate()}.
\item
  Remove segments with a duration less than 3 minutes
\item
  inspect your data visually
\end{enumerate}

\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-73-1.pdf}

\hypertarget{task-5-similarity-measures}{%
\subsection{Task 5: Similarity measures}\label{task-5-similarity-measures}}

Import the dataset \texttt{pedestrian.csv} (available on moodle) as a dataframe (you don't need an \texttt{sf} object). It it a set of six different but similar trajectories from pedestrians walking on a path. Explore this data visually.

We will analyse these trajectories with the package \texttt{SimilarityMeasures}, always comparing trajectory 1 pairwise to the other trajectories 2-6. For this task, explore the trajectories first and get an idea on how the pedestrians moved. We step away from using the wild boar data for this task because our animals don't express the type of similarity we want to illustrate here. Also, using the constructed pedestrian data allows us illustrating very typical similarity issues, that are picked-up in different ways by the different similarity measures. In later exercises we will get back to our wild boar!

\begin{figure}
\centering
\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-77-1.pdf}
\caption{\label{fig:unnamed-chunk-77}Comparing Trajectories 1 and 2}
\end{figure}

\begin{figure}
\centering
\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-78-1.pdf}
\caption{\label{fig:unnamed-chunk-78}Comparing Trajectories 1 and 3. Some positions are labelled with the position index to illustrate the direction of movement per trajectory.}
\end{figure}

\begin{figure}
\centering
\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-79-1.pdf}
\caption{\label{fig:unnamed-chunk-79}Comparing Trajectories 1 and 4}
\end{figure}

\begin{figure}
\centering
\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-80-1.pdf}
\caption{\label{fig:unnamed-chunk-80}Comparing Trajectories 1 and 5}
\end{figure}

\begin{figure}
\centering
\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-81-1.pdf}
\caption{\label{fig:unnamed-chunk-81}Comparing Trajectories 1 and 6}
\end{figure}

\hypertarget{task-6-calculate-similarity}{%
\subsection{Task 6: Calculate similarity}\label{task-6-calculate-similarity}}

Calculate the similarity between trajectory 1 and trajectories 2-6. Use the different similarity measures in the package \texttt{SimilarityMeasures}. Visualize your results and try to understand the different results with respect to your reading of Alan Both (\protect\hyperlink{ref-both2018}{2018}). Can you see connections between the properties of the trajectories and the similarity values computed by the different measures?

Note:

\begin{itemize}
\tightlist
\item
  All functions in the package need matrices as input, with one trajectory per matrix.
\item
  \texttt{LCSS}takes very long to compute. The accuracy of the algorithm (\texttt{pointSpacing\ =} ,\texttt{pointDistance\ =} and \texttt{errorMarg\ =}) can be varied to provide faster calculations. Please see Vlachos, Gunopoulos, and Kollios (\protect\hyperlink{ref-vlachos2002}{2002}) for more information.
\end{itemize}

\begin{figure}
\centering
\includegraphics{patterns-and-trends_files/figure-latex/unnamed-chunk-85-1.pdf}
\caption{\label{fig:unnamed-chunk-85}Comparing Trajectory 1 to trajectories 2 to 6}
\end{figure}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-both2018}{}%
Alan Both, Matt Duckham, Kevin Buchin. 2018. ``A Comparative Analysis of Trajectory Similarity Measures: Recommendations for Selection and Use.''

\leavevmode\hypertarget{ref-laube2011}{}%
Laube, Patrick, and Ross S. Purves. 2011. ``How Fast Is a Cow? Cross - Scale Analysis of Movement Data.'' \emph{Transactions in GIS} 15 (3): 401--18. \url{https://doi.org/10.1111/j.1467-9671.2011.01256.x}.

\leavevmode\hypertarget{ref-vlachos2002}{}%
Vlachos, Michail, Dimitrios Gunopoulos, and George Kollios. 2002. ``Discovering Similar Multidimensional Trajectories.'' In \emph{Proceedings of the 18th International Conference on Data Engineering}, 673. ICDE '02. Washington, DC, USA: IEEE Computer Society. \url{http://dl.acm.org/citation.cfm?id=876875.878994}.

\leavevmode\hypertarget{ref-wickham2017}{}%
Wickham, Hadley, and Garrett Grolemund. 2017. \emph{R for Data Science: Import, Tidy, Transform, Visualize, and Model Data}. 1st ed. O'Reilly Media, Inc.


\end{document}
