# Exercise 2
<!-- Enrich trajectories (step length, speed, 5min/3hrs) -->
<!-- Simple multi-scale analysis (with dplyr summarize for 5min and 3hrs) -->
<!-- Moving windows -->
<!-- Map back in space -->


## Learning Outcomes
- You understand the dplyr functions `mutate`, `summarise` and `group_by` and can apply them to `sf` objects
- You can derive movement parameters (`timelag`, `steplength`, `speed`) from trajectory data.
- You can re-sample your trajectory data for cross scale movement analysis. 

## Prerequisites
Readings Skills from "R for Data Science" [@wickham2017]:

- RS2.1 Chap3 Data Transformation with `dplyr` (31p, 43-76)
- RS2.2 Chap10 Relational data with `dplyr` (21p, 171-193)
- RS2.3 Chap14 Pipes with `magrittr` (6p, 261-268)

Readings Theory

- R2.1 @laube2011: How fast is a cow? cross - scale analysis of movement data.

## Preperation

Install the package `zoo` to get access to the rolling window functions for last exercise. Also, install the package `CMAtools` where we have put together some helper functions that simplify some tasks in this course. The package `CMAtools` is not on CRAN, and we need to install it similar to how we installed the newest version of `ggplot` last week. Since it is not on the official Git hub page either, but on the ZHAW owned Git hub server, the syntax for installation is slightly different (see code below).


```{r, echo = T, include = T, eval = F}
install.packages("zoo")

devtools::install_git("https://github.engineering.zhaw.ch/PatternsTrendsEnvironmentalData/CMAtools.git")
```

Note: 

- If you want to understand what the functions in CMAtools do, you can either check the package documentation (`help(package = "CMAtools")`) or look at the functions [GIThub site](https://github.engineering.zhaw.ch/PatternsTrendsEnvironmentalData/CMAtools). 
- We will be extending this package regularly throughout this course. Note: You will have to regularly reinstall the package with the code below in order to update your local version of the package.

Open your R Project from last week. Either run your own script from last week or the following lines to bring the data to the form we need it for today exercise.

```{r, echo = T, include = T, eval = T}
library(tidyverse)
library(sf)

wildschwein_BE <- read_delim("../CMA_FS2018_Filestorage/wildschwein_BE.csv",",")

wildschwein_BE = st_as_sf(wildschwein_BE, coords = c("Long", "Lat"), crs = 4326,remove = FALSE)

wildschwein_BE <- st_transform(wildschwein_BE, 2056)
```



```{r, purl = F}
wildschwein_BE <- ungroup(wildschwein_BE)
```


## Demo Tidyverse

Depending on your knowledge of `R`, getting an overview of the data we imported last week might have been quite a challenge. Surprisingly enough, importing, cleaning and exploring your data can be the most challenging, time consuming part of a project. RStudio and the tidyverse offer many helpful tools to make this part easier (and more fun). You have read chapters on `dplyr` and `magrittr` as a preparation for this Exercise. Before we start with the Exercise however, this demo illustrates a simple approach offered by tidyverse which is applicable to sf-objects.

Assume we want to calculate the timelag in between subsequent positions. To achieve this we can use the function `difftime()` combined with `lead()` from `dplyr`. Let's look at these functions one by one.

### `difftime`

`difftime` takes two `POSIXct` values.


```{r}
## Demo Tidyverse ################
```


```{r, echo = T, include = T, eval = T}
now <- Sys.time()

later <- now + 10000

time_difference <- difftime(later,now)
```


```{r}
time_difference
```

You can also specify the unit of the output.

```{r, echo = T, include = T, eval = T}
time_difference <- difftime(later,now,units = "mins")
```
```{r}
time_difference
```


`difftime` returns an object of the Class `difftime`. However in our case, numeric values would be more handy than the Class `difftime`. So we'll wrap the command in `as.numeric()`:
```{r, echo = T, include = T, eval = T}
str(time_difference)
```



```{r, echo = T, include = T, eval = T}
time_difference <- as.numeric(difftime(later,now,units = "mins"))

str(time_difference)

```

### `lead()` / `lag()`


`lead()` and `lag()` return a vector of the same length as the input, just offset by a specific number of values (default is 1). Consider the following sequence:

```{r, echo = T, include = T, eval = T}
numbers <- 1:10

numbers
```

We can now run `lead()` and `lag()` on this sequence to illustrate the output. `n =` specifies the offset, `default =` specifies the default value used to "fill" the emerging "empty spaces" of the vector.

```{r, echo = T, include = T, eval = T}
lead(numbers)

lead(numbers,n = 2)

lag(numbers)

lag(numbers,n = 5)

lag(numbers,n = 5, default = 0)
```

This helps us performing operations on subsequent values in a vector (or rows in a table). You can think of this a little bit like a moving temporal window that moves along the trajectory, or down the rows of a table respectively.

```{r}
lead(numbers)-numbers
```


### `mutate()`
Using the above functions (`difftime()` and `lead()`), we can calculate the time lag, that is, the time difference between subsequent positions:

```{r, echo = T, include = T, eval = T}
wildschwein_BE$timelag  <- as.numeric(difftime(lead(wildschwein_BE$DatetimeUTC),wildschwein_BE$DatetimeUTC,units = "secs"))

```

We mention `wildschwein_BE` three times in this function, which is complicated. Instead, we can use `mutate()` to simplify the syntax:

```{r, echo = T, include = T, eval = T}
wildschwein_BE <- mutate(wildschwein_BE,timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")))
```


### `group_by()`

Now let's have a look at the vector created before:
```{r, echo = T, include = T, eval = T}
summary(wildschwein_BE$timelag)
```

These values don't make much sense: some are negative (which should not be the case) and some are very high (which would indicate large data gaps and should not be the case either). The reason for this result is that we did not consider that `timelag` should just be calculated between subsequent rows *of the same individual*. We can implement this by using `group_by()` (just as if calculating the convex hull last week). 

```{r, echo = T, include = T, eval = T}
wildschwein_BE <- group_by(wildschwein_BE,TierID)
```

After adding this grouping variable, calculating the timelag automatically accounts for the individual trajectories.

```{r, echo = T, include = T, eval = T}
wildschwein_BE <- mutate(wildschwein_BE,timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")))

summary(wildschwein_BE$timelag)
```



### `summarise()`

`summary()` returned the metrics over all individuals. If we want to summarise our data and get metrics *per animal*, we can use the `dplyr` function `summarise()`. In contrast to `mutate()`, which just adds a new column to the dataset, `summarise()` "collapses" the data to one row per individual (specified by `group_by`).

```{r,, echo = T, eval = F, include= T}
summarise(wildschwein_BE, mean = mean(timelag, na.rm = T))
```

The above operation works fine on normal `data.frames`, but since `wildschwein_BE` is also an `sf` object, `summarise` actually merges all the points to a multipoint geometry, which takes a long time to calculate. In order to prevent this, we can wrap the `sf` object in `as.data.frame` which removes the spatial attribute. Regrettably, it also removes the `group_by` variable, which we need to set again. The command therefore now reads: 

```{r, echo = T, include = T, eval = T}
summarise(group_by(as.data.frame(wildschwein_BE),TierID), mean_timelag = mean(timelag, na.rm = T))
```



### Piping 
The code above hard to read, since it has so many nested functions which need to be read from the inside out. In order to make code readable in a more human-friendly way, we can use the piping command `%>%` from `magrittr`, which is included in `dplyr` and the `tidyverse`. The above code then looks like this:

```{r, echo = T, include = T, eval = T}
wildschwein_BE %>%                     # Take wildschwein_BE...
  as.data.frame() %>%                  # ...convert it to a data.frame...
  group_by(TierID) %>%                 # ...group it by TierID
  summarise(                           # Summarise the data...
    mean_timelag = mean(timelag,na.rm = T) # ...by calculating the mean timelag
  )
```


### Bring it all together...

Here is the same approach with a different, smaller dataset:

```{r, echo = T, include = T, eval = T}
pigs = data.frame(
  TierID=c(8001,8003,8004,8005,8800,8820,3000,3001,3002,3003,8330,7222),
  sex=c("M","M","M","F","M","M","F","F","M","F","M","F"),
  age=c("A","A","J","A","J","J","J","A","J","J","A","A"),
  weight=c(50.755,43.409,12.000,16.787,20.987,25.765,22.0122,21.343,12.532,54.32,11.027,88.08)
)

pigs

pigs %>%
    summarise(         
    mean_weight = mean(weight)
  )

pigs %>%
  group_by(sex) %>%
  summarise(         
    mean_weight = mean(weight)
  )

pigs %>%
  group_by(sex,age) %>%
  summarise(         
    mean_weight = mean(weight)
  )

```



## Tasks and Inputs

### Task 1: Getting an overview

Calculate the time difference between subsequent rows as described in the demo (column `timelag`)
First, inspect your data in more detail. Try to answer the following questions:

- How many individuals were tracked? 
- How long were the individual tracked? Are there gaps?
- Were all individuals tracked concurrently or sequentially? 
- What is the temporal sampling interval between the locations?


Here are some exemplary visualisation you could produce to answer these questions. Can you now answer the above questions?
```{r, echo = F, include=T, eval = T}
## Task 1 ####################

wildschwein_BE <- wildschwein_BE %>%
  mutate(timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")))

ggplot(wildschwein_BE, aes(DatetimeUTC,TierID)) +
  geom_line()

ggplot(wildschwein_BE, aes(timelag)) +
  geom_histogram(binwidth = 50) +
  lims(x = c(0,15000)) +
  scale_y_log10()
  

wildschwein_BE[1:50,] %>%
  ggplot(aes(DatetimeUTC,timelag)) +
  geom_line() +
  geom_point()


```



### Input: Geometry as columns

Last week, we transformed our data from a `data.frame` to an `sf` object. This turned our `Lat`/`Long` Columns into a single geometry (list) column. While this is very handy for many spatial operations, accessing the coordinates directly becomes difficult. We therefore suggest storing the information twice, once as a geometry and once as a numeric value. We already have `WGS84` as numeric columns, but not yet the `CH1903+ LV95` coordinates. 

```{r, echo = F, include=T, eval = T}

wildschwein_BE %>%
  dplyr::select(-CollarID,-TierName) %>%
  as.data.frame() %>%
  slice(1:10)

```

Let's do the same for the `CH1903+ LV95`-values, as we will need the values in columns for our next task. First, we have to extract the Coordinates using `st_coordinates()`. We can store these values in a new variable and display them:

```{r, echo = T, eval = T, include=T}
# Store coordinates in a new variable
coordinates <- st_coordinates(wildschwein_BE)

head(coordinates)
```

Note that that the column are named `X` and `Y`, while [`CH1903+ LV95`](https://www.swisstopo.admin.ch/de/wissen-fakten/geodaesie-vermessung/neue-koordinaten.html) names the Axes `E` and `N`: let's rename the columns appropriately. After this, we can use `cbind()` to "glue" the columns to our original `sf`-object.

```{r, echo = T, eval = T, include=T}
colnames(coordinates) <- c("E","N")

wildschwein_BE <- cbind(wildschwein_BE,coordinates)
```


### Task 2: Deriving movement parameters I: Euclidean Distance and Speed

In this task we will derive some additional movement parameters from our trajectories. Note, so far our trajectories only consist of a list of time-stamped spatial locations. So let's calculate the animal's speed based on the distance and timelag in between two subsequent locations. 

- You can use the function `euclid()` from the `CMAtools` package to calculate Euclidean distances between subsequent rows. Use `?euclid` to see what the function expects and returns. 
- use `lead(E,1)` to address the the row `n+1`
- make sure you're clear in what unit you are measuring speed. Meters per second is a SI base unit, but might be unhandy for the speeds travelled by wild boar.

```{r}
## Task 2 ####################


library(CMAtools)

wildschwein_BE <- wildschwein_BE %>%
  group_by(TierID) %>%
  mutate(
    steplength = euclid(lead(E, 1),lead(N, 1),E,N),
    speed = steplength/timelag
  )



```




### Task 3: Cross-scale movement analysis

@laube2011 analyse animal movement across different scales (see below). We will do the same on a *subset* of our data.

![@laube2011: *Black points are used in calculation of movement parameters (e.g. speed) at a given termporal scale.*](02_Images/laube_2011_2.jpg)

#### Filter
To do so, filter your data to positions with a sampling interval between 40 and 60 seconds and save it to a new variable (we will use `wildschwein_BE_1`). From this subset, take the first 100 positions[^201] for the following task. 

[^201]: In the solution (and the graphics), we actually use locations 2-100 for aesthetical reasons

If you like to stick to the `tidyverse` approach, you can use `slice()` to subset the dataset by row number. Slice takes an integer vector. Eg: `slice(dataset, 1:10)`, returns the first 10 rows of a dataset, `slice(dataset, c(1,5,10))` returns the 1^st^, 5^th^ and 10^th^ value of a dataset.

```{r}

## Task 3 ####################################

wildschwein_BE_1 <- wildschwein_BE%>%
  filter(timelag > 40 & timelag < 80) %>%
  slice(2:100)
```

#### Resample 
Now manually reduce the granularity of our sampling interval by selecting samples every 3^rd^, 6^th^ and 9^th^ minute. 

- You can use `slice()` again for this task by providing an integer vector (with `seq()`) in the desired frequency
- Save each re-sampled dataset in a new variable. We will use `wildschwein_BE_3`, `wildschwein_BE_6` and `wildschwein_BE_9`.


```{r}
wildschwein_BE_3 <- wildschwein_BE_1 %>%
  slice(seq(1,nrow(.),3)) # the dot (".") represents the piped dataset

wildschwein_BE_6 <- wildschwein_BE_1 %>%
  slice(seq(1,nrow(.),6))


wildschwein_BE_9 <- wildschwein_BE_1 %>%
  slice(seq(1,nrow(.),9))
```

You should now have  4 datasets with different number of rows:

```{r, echo = T, include = T, eval = T}
nrow(wildschwein_BE_1)
nrow(wildschwein_BE_3)
nrow(wildschwein_BE_6)
nrow(wildschwein_BE_9)
```


#### Update derived parameters

`timelag`, `steplength` and `speed` now have to be recalculated for the three re-sampled datasets. Do so as we illustrated in the Chapter *Demo*. 


```{r}
wildschwein_BE_3 <- wildschwein_BE_3 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = euclid(lead(E, 1),lead(N, 1),E,N),
    speed = steplength/timelag
  )

wildschwein_BE_6 <- wildschwein_BE_6 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = euclid(lead(E, 1),lead(N, 1),E,N),
    speed = steplength/timelag
  )


wildschwein_BE_9 <- wildschwein_BE_9 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = euclid(lead(E, 1),lead(N, 1),E,N),
    speed = steplength/timelag
  )

```



#### Visualize 
Compare the speeds in a line plot and visualize the trajectories in a map (see examples below). Interpret the line plot, what do the different lines for the different temporal granularities tell you?

We've stored the geographic location of our point in the trajectory in three different forms in our dataset. Once as a `geometry`, once as `E`/`N` and once as `lat`/`long`. In our view, it is most practical to use the `E`/`N` (integer) columns of our data to map them in this task

- `geom_sf()` does not plot lines, just points
- Therefore, use `geom_path()` *and* `geom_point()` rather than `geom_sf()` within `ggplot`
- In contrast to `geom_sf()`, you have to explicitly specify  the `x`/`y` columns (in our case `E`/`N`) with `geom_path()`/`geom_point()`
- `geom_line()` does not work when mapping trajectory data, since it connects the observations *in order of the variable on the x axis*. `geom_path()` connects the observations in the order in which they appear in the data


```{r, echo = F, include = T,eval = T}



ggplot() +
  geom_point(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = wildschwein_BE_3, aes(E,N, colour = "3 minutes")) +
  geom_path(data = wildschwein_BE_3, aes(E,N, colour = "3 minutes")) +
  labs(color="Trajectory", title = "Comparing original- with 3 minutes-resampled data")  +
  theme_minimal()

ggplot() +
  geom_point(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = wildschwein_BE_6, aes(E,N, colour = "6 minutes")) +
  geom_path(data = wildschwein_BE_6, aes(E,N, colour = "6 minutes")) +
  labs(color="Trajectory", title = "Comparing original- with 6 minutes-resampled data") +
  theme_minimal()

ggplot() +
  geom_point(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = wildschwein_BE_9, aes(E,N, colour = "9 minutes")) +
  geom_path(data = wildschwein_BE_9, aes(E,N, colour = "9 minutes"))+
  labs(color="Trajectory", title = "Comparing original- with 9 minutes-resampled data") +
  theme_minimal()


ggplot() +
  geom_line(data = wildschwein_BE_1, aes(DatetimeUTC,speed, colour = "1 minute")) +
  geom_line(data = wildschwein_BE_3, aes(DatetimeUTC,speed, colour = "3 minutes")) +
  geom_line(data = wildschwein_BE_6, aes(DatetimeUTC,speed, colour = "6 minutes")) +
  geom_line(data = wildschwein_BE_9, aes(DatetimeUTC,speed, colour = "9 minutes")) +
  labs(x = "Time",y = "Speed (m/s)", title = "Comparing derived speed at different sampling intervals") +
  theme_minimal()

``` 


 
 




### Task 4: Deriving movement parameters II: Rolling window functions


A different approach would be to *smoothen* the derived parameters using a [moving window function](https://docs.wavefront.com/images/5sec_moving_window.png). The `zoo` package offers a variate of moving window functions (`roll_*`). Use `roll_mean()` to smooth the calculated speed. Familiarise yourself with this function by working on some dummy data, for example:

```{r}
## Task 4 ####################
```


```{r, echo = T, eval = T, include= T}

library(zoo)

example <- rnorm(10)
rollmean(example,k = 3,fill = NA,align = "left")
rollmean(example,k = 4,fill = NA,align = "left")

```

Now run `rollmean`on the `speed` variable of the subset (`wildschwein_BE_1`). Visualize the output from your moving windows and compare different window sizes (`k = `).


```{r}
wildschwein_BE_1 <- wildschwein_BE_1 %>%
  mutate(
    speed3 = rollmean(speed,3,NA,align = "left"),
    speed6 = rollmean(speed,6,NA,align = "left"),
    speed9 = rollmean(speed,9,NA,align = "left")
  )

wildschwein_BE_1 %>%
  gather(key,val,c(speed,speed3,speed6,speed9)) %>%
  ggplot(aes(DatetimeUTC,val,colour = key,group = key)) +
  # geom_point() +
  geom_line() 
```


### Task 5 (optional): Calculate turning angles

Just like we did with `speed` in tasks 2 - 4, we could do the same with turning angles of the trajectory. If you like a challenge, try to calculate these with the same approach! 
`CMAtools` has the function `turning_angle()`[^20]. Here is an example on some dummy data. We represent the turning angle as the clockwise, angular offset from moving straight ahead. 

[^20]: We haven't tested the function extensively yet and are happy for feedback. If you want to have a look at the function, check our [Git hub site](https://github.engineering.zhaw.ch/PatternsTrendsEnvironmentalData/CMAtools/blob/master/R/spatial.R)

```{r, echo = T, include=T, eval = T}

library(grid) # just for the arrows
set.seed(20)
data.frame(x = cumsum(rnorm(10)),y = cumsum(rnorm(10))) %>%
  mutate(angle = as.integer(turning_angle(x,y))) %>%
  ggplot(aes(x,y)) +
  geom_segment(aes(x = lag(x), y = lag(y), xend = x,yend = y),arrow = arrow(length = unit(0.5,"cm"))) +
  geom_label(aes(label = paste0(angle,"°")),alpha = 0.4,nudge_x = 0.2, nudge_y = 0.2) +
  coord_equal()

```



```{r code=readLines('01_R_Files/purl_all_rmd.R'), echo = F, include=F, eval=T}
```




<!-- ## Solutions (RCode) -->

<!-- ```{r code=readLines('12_Week2/RFiles/W02_01_Exercise.R'), results='asis', echo = T, include=T, eval=F} -->
<!-- ``` -->
