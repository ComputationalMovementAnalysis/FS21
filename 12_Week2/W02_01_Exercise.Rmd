# Exercise 2

## Learning Outcomes
- You understand the dplyr functions `mutate`, `summarise` and `group_by` and can apply them to `sf` objects
- You can derive movement parameters (`timelag`, `steplength`, `speed`) from trajectory data.
- You can re-sample your trajectory data for cross-scale movement analysis. 

## Prerequisites
Readings Skills from "R for Data Science" [@wickham2017]:

- RS2.1 Chap3 Data Transformation with `dplyr` (31p, 43-76)
- RS2.2 Chap10 Relational data with `dplyr` (21p, 171-193)
- RS2.3 Chap14 Pipes with `magrittr` (6p, 261-268)

Readings Theory

- R2.1 @laube2011: How fast is a cow? cross - scale analysis of movement data.

## Preperation

```{r}
## Preperation #################################################################
```


Install the package `zoo` to get access to the rolling window functions for last exercise. 


```{r, echo = T, include = T, eval = F, purl = F}
install.packages("zoo")

```


Import the wild boar data and convert it to an `sf` object with CH1903+ LV95 Coordinates. Either run your own script from last week or the following lines to bring the data to the form we need it for today exercise.

```{r, echo = T, include = T, eval = T}
library(tidyverse)
library(sf)
library(lubridate)

wildschwein_BE <- read_delim("00_Rawdata/wildschwein_BE.csv",",")

wildschwein_BE = st_as_sf(wildschwein_BE, 
                          coords = c("Long", "Lat"), 
                          crs = 4326)

wildschwein_BE <- st_transform(wildschwein_BE, 2056)
```

## Demo Tidyverse
```{r}
## Demo Tidyverse ##############################################################
```

Depending on your knowledge of `R`, getting an overview of the data we imported last week might have been quite a challenge. Surprisingly enough, importing, cleaning and exploring your data can be the most challenging, time consuming part of a project. RStudio and the tidyverse offer many helpful tools to make this part easier (and more fun). You have read chapters on `dplyr` and `magrittr` as a preparation for this exercise. Before we start with the exercise however, this demo illustrates a simple approach offered by tidyverse which is applicable to sf-objects.

Assume we want to calculate the timelag between subsequent positions. To achieve this we can use the function `difftime()` combined with `lead()` from `dplyr`. Let's look at these functions one by one.

### `difftime`

`difftime` takes two `POSIXct` values.


```{r, echo = T, include = T, eval = T}
now <- Sys.time()

later <- now + 10000

time_difference <- difftime(later,now)
```


```{r}
time_difference
```

You can also specify the unit of the output.

```{r, echo = T, include = T, eval = T}
time_difference <- difftime(later,now,units = "mins")
```

```{r}
time_difference
```


`difftime` returns an object of the Class `difftime`. However in our case, numeric values would be more handy than the Class `difftime`. So we'll wrap the command in `as.numeric()`:
```{r, echo = T, include = T, eval = T}
str(time_difference)
```



```{r, echo = T, include = T, eval = T}
time_difference <- as.numeric(difftime(later,now,units = "mins"))

str(time_difference)

```

### `lead()` / `lag()`


`lead()` and `lag()` return a vector of the same length as the input, just offset by a specific number of values (default is 1). Consider the following sequence:

```{r, echo = T, include = T, eval = T}
numbers <- 1:10

numbers
```

We can now run `lead()` and `lag()` on this sequence to illustrate the output. `n =` specifies the offset, `default =` specifies the default value used to "fill" the emerging "empty spaces" of the vector.

```{r, echo = T, include = T, eval = T}
lead(numbers)

lead(numbers,n = 2)

lag(numbers)

lag(numbers,n = 5)

lag(numbers,n = 5, default = 0)
```

This helps us performing operations on subsequent values in a vector (or rows in a table). You can think of this a little bit like a moving temporal window that moves along the trajectory, or down the rows of a table respectively.

```{r}
lead(numbers)-numbers
```


### `mutate()`
Using the above functions (`difftime()` and `lead()`), we can calculate the time lag, that is, the time difference between subsequent positions:

```{r, echo = T, include = T, eval = T}

wildschwein_BE$timelag  <- as.numeric(difftime(lead(wildschwein_BE$DatetimeUTC),
                                               wildschwein_BE$DatetimeUTC,
                                               units = "secs"))

```

We mention `wildschwein_BE` three times in this function, which is complicated. Instead, we can use `mutate()` to simplify the syntax:

```{r, echo = T, include = T, eval = T}
wildschwein_BE <- mutate(wildschwein_BE,timelag = as.numeric(difftime(lead(DatetimeUTC),
                                                                      DatetimeUTC,
                                                                      units = "secs")))
```


### `group_by()`

Now let's have a look at the vector created before:
```{r, echo = T, include = T, eval = T}
summary(wildschwein_BE$timelag)
```

These values don't make much sense: some are negative (which should not be the case) and some are very high (which would indicate large data gaps and should not be the case either). The reason for this result is that we did not consider that `timelag` should just be calculated between subsequent rows *of the same individual*. We can implement this by using `group_by()` (just as if calculating the convex hull last week). 

```{r, echo = T, include = T, eval = T}
wildschwein_BE <- group_by(wildschwein_BE,TierID)
```

After adding this grouping variable, calculating the timelag automatically accounts for the individual trajectories.

```{r, echo = T, include = T, eval = T}
wildschwein_BE <- mutate(wildschwein_BE,timelag = as.numeric(difftime(lead(DatetimeUTC),
                                                                      DatetimeUTC,
                                                                      units = "secs")))

summary(wildschwein_BE$timelag)
```



### `summarise()`

`summary()` returned the metrics over all individuals. If we want to summarise our data and get metrics *per animal*, we can use the `dplyr` function `summarise()`. In contrast to `mutate()`, which just adds a new column to the dataset, `summarise()` "collapses" the data to one row per individual (specified by `group_by`).

```{r,, echo = T, eval = F, include= T}
summarise(wildschwein_BE, mean = mean(timelag, na.rm = T))
```

The above operation works fine on normal `data.frames`, but since `wildschwein_BE` is also an `sf` object, `summarise` actually merges all the points to a multipoint geometry, which takes a long time to calculate. In order to prevent this, we can set the objects geometry to `NULL`, which removes the spatial attribute.
```{r, echo = T, include = T, eval = T}

summarise(st_set_geometry(wildschwein_BE,NULL), mean_timelag = mean(timelag, na.rm = T))
```



### Piping 
The code above may be a bit hard to read, since it has so many nested functions which need to be read from the inside out. In order to make code readable in a more human-friendly way, we can use the piping command `%>%` from `magrittr`, which is included in `dplyr` and the `tidyverse`. The above code then looks like this:

```{r, echo = T, include = T, eval = T}

wildschwein_BE %>%                     # Take wildschwein_BE...
  st_set_geometry(NULL) %>%            # ...remove the geometry column...
  group_by(TierID) %>%                 # ...group it by TierID
  summarise(                           # Summarise the data...
    mean_timelag = mean(timelag,na.rm = T) # ...by calculating the mean timelag
  )
```


### Bring it all together...

Here is the same approach with a different, smaller dataset:

```{r, echo = T, include = T, eval = T}
pigs = data.frame(
  TierID=c(8001,8003,8004,8005,8800,8820,3000,3001,3002,3003,8330,7222),
  sex=c("M","M","M","F","M","M","F","F","M","F","M","F"),
  age=c("A","A","J","A","J","J","J","A","J","J","A","A"),
  weight=c(50.755,43.409,12.000,16.787,20.987,25.765,22.0122,21.343,12.532,54.32,11.027,88.08)
)

pigs

pigs %>%
    summarise(         
    mean_weight = mean(weight)
  )

pigs %>%
  group_by(sex) %>%
  summarise(         
    mean_weight = mean(weight)
  )

pigs %>%
  group_by(sex,age) %>%
  summarise(         
    mean_weight = mean(weight)
  )

```


## Tasks and Inputs

### Task 1: Getting an overview
```{r}
## Task 1 ######################################################################
```

Calculate the time difference between subsequent rows as described in the demo (column `timelag`).
First, inspect your data in more detail. Try to answer the following questions:

- How many individuals were tracked? 
- For how long were the individual tracked? Are there gaps?
- Were all individuals tracked concurrently or sequentially? 
- What is the temporal sampling interval between the locations?


Here are some exemplary visualisation you could produce to answer these questions. Can you now answer the above questions?

```{r, echo = F, include=T, eval = T}



wildschwein_BE <- wildschwein_BE %>%
  mutate(timelag = as.numeric(difftime(lead(DatetimeUTC),
                                       DatetimeUTC,
                                       units = "secs")))

ggplot(wildschwein_BE, aes(DatetimeUTC,TierID)) +
  geom_line()

ggplot(wildschwein_BE, aes(timelag)) +
  geom_histogram(binwidth = 50) +
  lims(x = c(0,15000)) +
  scale_y_log10()
  

wildschwein_BE %>%
  filter(year(DatetimeUTC)  == 2014) %>%
  ggplot(aes(DatetimeUTC,timelag, colour = TierID)) +
  geom_line() +
  geom_point()
  
```


### Input: Geometry as columns
```{r}
## Input: Geometry as Columns ##################################################
```


Last week, we transformed our data from a `data.frame` to an `sf` object. This turned our `Lat`/`Long` columns into a single geometry (list) column. While this is very handy for many spatial operations, accessing the coordinates directly becomes difficult. We therefore suggest storing the information twice, once as a geometry and once as a numeric value. To do this, we have to extract the Coordinates using `st_coordinates()`. We can store these values in a new variable and display them:

```{r, echo = T, eval = T, include=T}
# Store coordinates in a new variable

coordinates <- st_coordinates(wildschwein_BE)

head(coordinates)
```

Note that that the column are named `X` and `Y`, while [`CH1903+ LV95`](https://www.swisstopo.admin.ch/de/wissen-fakten/geodaesie-vermessung/neue-koordinaten.html) names the Axes `E` and `N`: let's rename the columns appropriately. After this, we can use `cbind()` to "glue" the columns to our original `sf`-object.

```{r, echo = T, eval = T, include=T}
colnames(coordinates) <- c("E","N")

wildschwein_BE <- cbind(wildschwein_BE,coordinates)

head(wildschwein_BE)
```

```{r}
#- chunkend
```

### Task 2: Deriving movement parameters I: Speed

```{r}
## Task 2 ######################################################################
```

In this task we will derive some additional movement parameters from our trajectories. So far our trajectories only consist of a list of time-stamped spatial locations. So let's calculate the animal's steplength based on the Euclidean distance between two subsequent locations. 

- You can calculate the Euclidean distance with the following formula: `sqrt((E1-E2)^2+(N1-N2)^2)`
- use `lead(E,1)` to address the the row `n+1` (i.e. E2)

```{r}
wildschwein_BE <- wildschwein_BE %>%
  group_by(TierID) %>%
  mutate(
    steplength = sqrt((E-lead(E))^2+(N-lead(N))^2)
  )
```

Why do we use `E` and `N` when calculating the Euclidean distance, and not `Lat`/`Long`? Now calculate the animals' speed between subsequent locations based on the steplength as calculated in the previous task and the timelag between the locations. What speed unit do you get?

```{r}
wildschwein_BE <- wildschwein_BE %>%
  group_by(TierID) %>%
  mutate(
    speed = steplength/timelag
  )
```



### Task 3: Cross-scale movement analysis

```{r}
## Task 3 ######################################################################

```


@laube2011 analyse animal movement across different scales (see below). We will do the same on a *subset* of our data.

![@laube2011: *Black points are used in calculation of movement parameters (e.g. speed) at a given termporal scale.*](02_Images/laube_2011_2.jpg)

#### Import "Caro60"

In the first task, we saw that the animals are sampled at different frequencies. To simplify the task, we've prepared a dataset that includes 200 locations of a single wild boar with a constant sampling interval of 60 seconds. Import this dataset named "caro60.csv" (available on moodle) just like you imported the other wild boar data. **NOTE:** We've converted the positions to CH1903+ LV95 for your convenience. Consider this when transforming to `sf`!
Save this data to a new variable (we will use `caro60`). 

```{r}
caro60 <- read_delim("00_Rawdata/caro60.csv",",") %>%
  st_as_sf(coords = c("E", "N"), crs = 2056, remove = FALSE)
  
```

#### Resample 

Now manually reduce the granularity of our sampling interval by selecting every 3^rd^, 6^th^ and 9^th^ position. 

If you like to stick to the `tidyverse` approach, you can use `slice()` to subset the dataset by row number. Slice takes an integer vector. Eg: `slice(dataset, 1:10)`, returns the first 10 rows of a dataset, `slice(dataset, c(1,5,10))` returns the 1^st^, 5^th^ and 10^th^ value of a dataset. Save each re-sampled dataset in a new variable. We will use `caro60_3`, `caro60_6` and `caro60_9`.


```{r}
caro60_3 <- caro60 %>%
  slice(seq(1,nrow(.),3)) # the dot (".") represents the piped dataset

caro60_6 <- caro60 %>%
  slice(seq(1,nrow(.),6))

caro60_9 <- caro60 %>%
  slice(seq(1,nrow(.),9))
```

You should now have  4 data sets with different number of rows:

```{r, echo = T, include = T, eval = T}
nrow(caro60)
nrow(caro60_3)
nrow(caro60_6)
nrow(caro60_9)
```


#### Update derived parameters

`timelag`, `steplength` and `speed` now have to be recalculated for the three re-sampled data sets. Do so as we illustrated in the Chapter *Demo*. 


```{r}

caro60 <- caro60 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = sqrt((E-lead(E))^2+(N-lead(N))^2),
    speed = steplength/timelag
  )

caro60_3 <- caro60_3 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = sqrt((E-lead(E))^2+(N-lead(N))^2),
    speed = steplength/timelag
  )

caro60_6 <- caro60_6 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = sqrt((E-lead(E))^2+(N-lead(N))^2),
    speed = steplength/timelag
  )


caro60_9 <- caro60_9 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = sqrt((E-lead(E))^2+(N-lead(N))^2),
    speed = steplength/timelag
  )

```



#### Visualize 
Compare the speeds in a line plot and visualize the trajectories in a map (see examples below). Interpret the line plot, what do the different lines for the different temporal granularities tell you?

We've stored the geographic location of our point in the trajectory in three different forms in our dataset. Once as a `geometry`, once as `E`/`N` and once as `lat`/`long`. In our view, it is most practical to use the `E`/`N` (integer) columns of our data to map them in this task

- `geom_sf()` does not plot lines, just points
- Therefore, use `geom_path()` *and* `geom_point()` rather than `geom_sf()` within `ggplot`
- In contrast to `geom_sf()`, you have to explicitly specify  the `x`/`y` columns (in our case `E`/`N`) with `geom_path()`/`geom_point()`
- `geom_line()` does not work when mapping trajectory data, since it connects the observations *in order of the variable on the x axis*. `geom_path()` connects the observations in the order in which they appear in the data


```{r, echo = F, include = T,eval = T}



ggplot() +
  geom_point(data = caro60, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = caro60, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = caro60_3, aes(E,N, colour = "3 minutes")) +
  geom_path(data = caro60_3, aes(E,N, colour = "3 minutes")) +
  labs(color="Trajectory", title = "Comparing original- with 3 minutes-resampled data")  +
  theme_minimal()

ggplot() +
  geom_point(data = caro60, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = caro60, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = caro60_6, aes(E,N, colour = "6 minutes")) +
  geom_path(data = caro60_6, aes(E,N, colour = "6 minutes")) +
  labs(color="Trajectory", title = "Comparing original- with 6 minutes-resampled data") +
  theme_minimal()

ggplot() +
  geom_point(data = caro60, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = caro60, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = caro60_9, aes(E,N, colour = "9 minutes")) +
  geom_path(data = caro60_9, aes(E,N, colour = "9 minutes"))+
  labs(color="Trajectory", title = "Comparing original- with 9 minutes-resampled data") +
  theme_minimal()


ggplot() +
  geom_line(data = caro60, aes(DatetimeUTC,speed, colour = "1 minute")) +
  geom_line(data = caro60_3, aes(DatetimeUTC,speed, colour = "3 minutes")) +
  geom_line(data = caro60_6, aes(DatetimeUTC,speed, colour = "6 minutes")) +
  geom_line(data = caro60_9, aes(DatetimeUTC,speed, colour = "9 minutes")) +
  labs(x = "Time",y = "Speed (m/s)", title = "Comparing derived speed at different sampling intervals") +
  theme_minimal()

``` 


### Task 4: Deriving movement parameters II: Rolling window functions

```{r}
## Task 4 ######################################################################
```


A different approach would be to *smoothen* the derived parameters using a [moving window function](https://docs.wavefront.com/images/5sec_moving_window.png). The `zoo` package offers a variate of moving window functions (`roll_*`). Use `roll_mean()` to smooth the calculated speed. Familiarise yourself with this function by working on some dummy data, for example:


```{r, echo = T, eval = T, include= T}
library(zoo)

example <- rnorm(10)
rollmean(example,k = 3,fill = NA,align = "left")
rollmean(example,k = 4,fill = NA,align = "left")


```

Now run `rollmean`on the `speed` variable of the subset (`caro60`). Visualize the output from your moving windows and compare different window sizes (`k = `).


```{r}
caro60 <- caro60 %>%
  mutate(
    speed3 = rollmean(speed,3,NA,align = "left"),
    speed6 = rollmean(speed,6,NA,align = "left"),
    speed9 = rollmean(speed,9,NA,align = "left")
  )

caro60 %>%
  gather(key,val,c(speed,speed3,speed6,speed9)) %>%
  ggplot(aes(DatetimeUTC,val,colour = key,group = key)) +
  # geom_point() +
  geom_line() 
```


### Task 5 (optional): Calculate turning angles
```{r}
## Task 5 ######################################################################
```

Just like we did with `speed` in tasks 2 - 4, we could do the same with turning angles of the trajectory. If you like a challenge, try to calculate these with the same approach! Warning: this task is pretty complex. Note, as this task is optional, you don't have to include it in your mandatory submission of Exercise 2!


```{r}
library(grid) # just for the arrows


# Advanced solution including the building of functions. Only for very motivated students!

euclid <- function(x1,y1,x2,y2){
  return(sqrt((x1-x2)^2+(y1-y2)^2))
}
turning_angle <- function(x,y,lead_lag = 1){
  if(length(x) < 3){stop("Minimum length of x and y is 3")}
  if(length(x) != length(y)){stop("x and y must be of the same length")}
  p1x <- lag(x,lead_lag)
  p1y <- lag(y,lead_lag)
  p2x <- x
  p2y <- y
  p3x <- lead(x,lead_lag)
  p3y <- lead(y,lead_lag)
  p12 <- euclid(p1x,p1y,p2x,p2y)
  p13 <- euclid(p1x,p1y,p3x,p3y)
  p23 <- euclid(p2x,p2y,p3x,p3y)
  rad <- acos((p12^2+p23^2-p13^2)/(2*p12*p23))
  grad <- (rad*180)/pi
  grad[p12 == 0 | p23 == 0] <- NA
  d <-  (p3x-p1x)*(p2y-p1y)-(p3y-p1y)*(p2x-p1x)
  d <- ifelse(d == 0,1,d)
  d[d>0] <- 1
  d[d<0] <- -1
  d[d==0] <- 1
  turning <- grad*d*-1+180
  return(turning)
}

# Running the functions on some dummy data:
set.seed(20)
data.frame(x = cumsum(rnorm(10)),y = cumsum(rnorm(10))) %>%
  mutate(angle = as.integer(turning_angle(x,y))) %>%
  ggplot(aes(x,y)) +
  geom_segment(aes(x = lag(x), y = lag(y), xend = x,yend = y),arrow = arrow(length = unit(0.5,"cm"))) +
  geom_label(aes(label = paste0(angle,"°")),alpha = 0.4,nudge_x = 0.2, nudge_y = 0.2) +
  coord_equal()
```




