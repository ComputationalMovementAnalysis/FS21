# Exercise 2
<!-- Enrich trajectories (step length, speed, 5min/3hrs) -->
<!-- Simple multi-scale analysis (with dplyr summarize for 5min and 3hrs) -->
<!-- Moving windows -->
<!-- Map back in space -->


## Learning Outcomes
- You understand the SAC approach in the context of tidyverse tools and can apply it to `sf` objects
- You can derive attributes from your data based on changes in the observed variables
- You can resample your data for multi scaled analyses 
<!-- TODO laup: learning outcomes so ok?  -->

## Prerequisites
Readings Skills from "R for Data Science" [@wickham2017]:

- RS2.1 Chap3 Data Transformation with `dplyr` (31p, 43-76)
- RS2.2 Chap10 Relational data with `dplyr` (21p, 171-193)
- RS2.3 Chap14 Pipes with `magrittr` (6p, 261-268)

Readings Theory

- R2.1 @laube2011: How fast is a cow? cross - scale analysis of movement data.

## Preperation

Open your R Project from last week. Load all libraries and run the script to import and clean your data. Install the package `zoo` to get access to the rolling window functions for last (optional) exercise. Also, install the package `CMAtools` where we have put together some helper functions so simplify some tasks in this course. The package `CMAtools` is not on CRAN, and we need to install it similar to how we installed the newest version of `ggplot` last week. Since it is not on the official GIThub page either, but on the ZHAW owned GIThub server, the syntax for installation is slightly different (see code below).
<!-- todo nils: prepare and upload sf object to moodle. Edit this text appropriately  -->

Note: 

- If you want to understand what the functions in CMAtools do, you can either check the package documentation (`help(package = "CMAtools")`) or look at the functions [GIThub site](https://github.engineering.zhaw.ch/PatternsTrendsEnvironmentalData/CMAtools). 
- We will be extending this package regularly within this course. Reinstall the package with the code below to update your local version of the package.

```{r, echo = T, include=T, eval=F}
install.packages("zoo")

devtools::install_git("https://github.engineering.zhaw.ch/PatternsTrendsEnvironmentalData/CMAtools.git")
```

```{r}
wildschwein_BE <- ungroup(wildschwein_BE)
```


## Demo Tidyverse

Depending on your knowledge of `R`, getting an overview of the data we imported last week might have been quite a challenge. Surprisingly enough, importing, cleaning and exploring your data can be the most challenging, time consuming part of a project. RStudio and the tidyverse offer many helpful tools to make this part easier (and more fun). You have read chapters on `dplyr` and `magrittr` as a preparation for this Exercise. Before we start with the Exercise however, this demo illustrates a simple approach offered by tidyverse which is applicable to sf-objects.

Assume we want to calculate the timelag in between subsequent positions. To achieve this we can use the function `difftime()` combined with `lead()` from `dplyr`. Let's look at these functions one by one.

### `difftime`

`difftime` takes two `POSIXct` values.


```{r}
## Demo Tidyverse ################
```


```{r, echo = T, eval = T, include= T}
now <- Sys.time()

later <- now + 10000

time_difference <- difftime(later,now)
```


```{r}
time_difference
```

You can also specify the unit of the output

```{r, echo = T, eval = T, include= T}
time_difference <- difftime(later,now,units = "mins")
```
```{r}
time_difference
```


`difftime` returns an object of the Class `difftime`. However in our case, numeric values would be more handy than the Class `difftime`. So we'll wrap the command in `as.numeric()`:
```{r, echo = T, eval = T, include= T}
str(time_difference)
```



```{r, echo = T, eval = T, include= T}
time_difference <- as.numeric(difftime(later,now,units = "mins"))

str(time_difference)

```

### `lead()` / `lag()`


`lead()` and `lag()` return a vector of the same length as the input, just offset by a specific number of values (default is 1). Consider the following sequence:

```{r, echo = T, eval = T, include= T}
numbers <- 1:10

numbers
```

We can now run `lead()` and `lag()` on this sequence to illustrate the output. `n =` specifies the offset, `default =` specifies the default value used to "fill" the vector.

```{r, echo = T, eval = T, include= T}
lead(numbers)

lead(numbers,n = 2)

lag(numbers)

lag(numbers,n = 5)

lag(numbers,n = 5, default = 0)
```

This helps us performing operations on subsequent values in a vector (or rows in a table)

```{r}
lead(numbers)-numbers
```


### `mutate()`
Using the above functions (`difftime()` and `lead()`), we can calculate the time difference between subsequent positions:

```{r, echo = T, eval = T, include= T}
wildschwein_BE$timelag  <- as.numeric(difftime(lead(wildschwein_BE$DatetimeUTC),wildschwein_BE$DatetimeUTC,units = "secs"))

```

We mention `wildschwein_BE` three times in this function, which is why we can use `mutate()`:

```{r, echo = T, eval = T, include= T}
wildschwein_BE <- mutate(wildschwein_BE,timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")))
```

Now let's have a look at this vector:
```{r, echo = T, eval = T, include= T}
summary(wildschwein_BE$timelag)
```

These values don't make much sense: some are negative (which should not be the case) and some are very high (which would indicate large data gaps and should not be the case either). The reason for this result is that we did not consider that `timelag` should just be calculated between subsequent rows *of the same individual*. We can implement this by using `group_by()` (just as if calculating the convex hull last week). 

```{r, echo = T, eval = T, include= T}
wildschwein_BE <- group_by(wildschwein_BE,TierID)
```

After adding this grouping variable, calculating the timelag automatically accounts for the individual trajectories.

```{r, echo = T, eval = T, include= T}
wildschwein_BE <- mutate(wildschwein_BE,timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")))

summary(wildschwein_BE$timelag)
```


Summary returned the metrics over all individuals. If we want to summarise our data and get metrics *per animal*, we can use the `dplyr` function `summarise()`. In contrast to `mutate()`, which just adds a new column to the dataset, `summarise()` "collapses" the data to one row per individual (specified by `group_by`).

```{r,, echo = T, eval = F, include= T}
summarise(wildschwein_BE, mean = mean(timelag, na.rm = T))
```

The above operation works fine on normal `data.frames`, but since `wildschwein_BE` is also an `sf` object, `summarise` actually merges all the points to a multipoint geometry, which takes a long time to calculate. In order to prevent this, we can wrap the `sf` object in `as.data.frame` which removes the spatial attribute. Regrettably, it also removes the `group_by` variable, which we need to set again. The command therefore goes like: 

```{r, echo = T, eval = T, include= T}
summarise(group_by(as.data.frame(wildschwein_BE),TierID), mean_timelag = mean(timelag, na.rm = T))
```


This code is hard to read, since it has so many nested functions which need to be read from the inside out. In order to make code readable in a more human-friendly way, we can use the piping command `%>%` from `magrittr`, which is included in `dplyr` and the `tidyverse`. The above code then looks like this:

```{r, echo = T, eval = T, include= T}
wildschwein_BE %>%                     # Take wildschwein_BE...
  as.data.frame() %>%                  # ...convert it to a data.frame...
  group_by(TierID) %>%                 # ...group it by TierID
  summarise(                           # Summarise the data...
    mean_timelag = mean(timelag,na.rm = T) # ...by calculating the mean timelag
  )
```





## Tasks and Inputs

<!-- Todo: Der Begriff Input in diesem Kontext verwirrt micht, bitte aendern (auch rückwirkend in Exercise 1) in 'Skills section'. Ich würd dann auch den Untertitel von 'Tasks and inputs' nur noch in 'tasks' ändern.  -->

### Task 1: Getting an Overview


First, inspect your data in more detail. Try to answer the following questions:

- How many individuals were tracked? 
- How long were the individual tracked? Are there gaps?
- Were all individuals tracked concurrently or sequentially? 
- What is the temporal sampling interval between the locations?


<!-- TODO: diese Grafiken werden nicht mit den Werkzeugen gelöst, die im Demo illustriert werden -->

Here are some exemplary visualisation you could produce to answer these questions. Can you now answer the above questions?
```{r, echo = F, include=T, eval = T}
## Task 1 ####################

ggplot(wildschwein_BE, aes(DatetimeUTC,TierID)) +
  geom_line()

ggplot(wildschwein_BE, aes(timelag)) +
  geom_histogram(binwidth = 50)

ggplot(wildschwein_BE, aes(timelag)) +
  geom_histogram(binwidth = 1) +
  lims(x = c(0,100)) +
  scale_y_log10()

wildschwein_BE[1:50,] %>%
  ggplot(aes(DatetimeUTC,timelag)) +
  geom_line() +
  geom_point()


```

### Input: `cut()` vector by intervals

For the next Task, we will need a function to split a continuous variable into specific intervals. For this, the function `cut()`is very handy. Let's introduce this function with a quick example. Assume we have a series of number that represent the ages of ten different people.

```{r}
## Input: cut vecotrs by intervals ####################
```


```{r, echo = T, eval = T, include = T}
ages <- c(20,25,18,13,53,50,23,43,68,40)
```
Let's say we want to split this into equal intervals of 10 years.

```{r, echo = T, eval = T, include = T}
breaks <- seq(0,50,10)

cut(ages,breaks = breaks)
```
Note:

- If a number does not fit within an interval defined by `breaks =`, `cut()` will return `NA` (as for example for the fifth element `53`).
- The default `labels` with `(` and `]` might seem a little ugly and puzzling at first, but in fact they are [a standard form of notating intervals in mathematics](https://en.wikipedia.org/wiki/Interval_%28mathematics%29#Notations_for_intervals).
- If you don't like `(` and `]`, you can:
  + specify your own labels with the argument `labels =` *or*
  + use the the function `labels_nice` we provide with the `CMAtools`-package
- Four thresholds (i.e. `breaks`) return three intervals (i.e. `lables`), as shown below.

```{r, echo = T, eval = T, include = T}

breaks <- c(0,30,60,100)

cut(ages, breaks = breaks, labels = c("young","middle aged","old"))

cut(ages, breaks = breaks, labels = CMAtools::labels_nice(breaks))


```



### Task 2: Making groups by sampling Interval

Now that we've established that we have different sampling intervals (Task 1), we have to segment our trajectories in such a way, that we can perform further analysis during specific sampling intervals only. If we measure speed, or turning angles, we have to be very clear on what temporal (an thus spatial) scale or granularity we are performing this analysis. 

We therefore have to define thresholds to group segments with a similar sampling interval. Explore the dataset in more detail (e.g. using histograms at different scales), and choose reasonable threshold values to group the trajectories into different sampling intervals. 

Note: 

- It might make more sense to choose narrow intervals at shorter time lags and wider intervals at longer time lags.
- Store the interval names in a new column named `samplingInt`
- explore the dataset by using a logarithmic `y-axis` (`scale_y_log10()`) and looking at the different parts of the `x-axis` seperately
- We will later filter the data by the sampling interval. We therefore recommend the use of `labels_nice()` from the package `CMAtools` for nicer, more intuitive labels.


```{r, echo = F, include = T, eval = T}
## Task 2 ####################

breaks <- c(0,40,80,300,600,1200,2500,3000,4000,7500,110000)


ggplot(wildschwein_BE, aes(timelag)) +
  geom_histogram(binwidth = 10) +
  lims(x = c(0,600)) +
  scale_y_log10() +
  geom_vline(xintercept = breaks, col = "red")

ggplot(wildschwein_BE, aes(timelag)) +
  geom_histogram(binwidth = 10) +
  lims(x = c(600,1200)) +
  scale_y_log10() +
  geom_vline(xintercept = breaks, col = "red")


ggplot(wildschwein_BE, aes(timelag)) +
  geom_histogram(binwidth = 10) +
  lims(x = c(1200,10000)) +
  scale_y_log10() +
  geom_vline(xintercept = breaks, col = "red")


wildschwein_BE <- wildschwein_BE %>%
  group_by(TierID) %>%
  mutate(
    samplingInt = cut(timelag,breaks = breaks,labels = CMAtools::labels_nice(breaks))
  ) 

# wildschwein_BE %>%
#   as.data.frame() %>%
#   group_by(samplingInt) %>%
#   summarise(
#     n = n()
#   ) %>%
#   ggplot(aes(samplingInt,n)) +
#   geom_bar(stat = "identity") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#   scale_y_log10()

# Todo: diesen Plot entfernen?
```


### Input: Geometry as columns

Last week, we transformed our data from a `data.frame` to an `sf` object. This turned our `Lat`/`Long` Columns into a single geometry (list) column. While this is very handy for many spatial operations, accessing the coordinates directly becomes difficult. We therefore suggest storing the information twice, once as a geometry and once as a numeric value. We did this for the values in `WGS84`, but not yet for `CH1903+ LV95`. 

```{r, echo = T, eval = T, include=T}

wildschwein_BE

```

Let's do the same for the `CH1903+ LV95`-values, as we will need the values in columns for our next task. First, we have to extract the Coordinates using `st_coordinates()`. We can store these values in a new variable and display them:

```{r, echo = T, eval = T, include=T}
# Store coordinates in a new variable
coordinates <- st_coordinates(wildschwein_BE)

head(coordinates)
```

Note that that the column are named `X` and `Y`, while [`CH1903+ LV95`](https://www.swisstopo.admin.ch/de/wissen-fakten/geodaesie-vermessung/neue-koordinaten.html) names the Axes `E` and `N`: let's rename the columns appropriately. After this, we can use `cbind()` to "glue" the columns to our original `sf`-object.

```{r, echo = T, eval = T, include=T}
colnames(coordinates) <- c("E","N")

wildschwein_BE <- cbind(wildschwein_BE,coordinates)
```


### Task 3: Deriving movement parameters I: Euclidean Distance and Speed

In this task we will derive some additional movement parameters from our trajectories. Note, so far our trajectories only consist of a list of time-stamped spatial locations. So let's calculate the animal's speed based on the distance and timelag in between two subsequent locations. 

- If you're working with `dplyr`, you can add `samplingInt` to `group_by()` (in addition to `TierID`) and so make sure you're not calculating speed across different sampling intervals. 
- You can use the function `euclid()` from the `CMAtools` package to calculate Euclidean distances between subsequent rows. Use `?euclid` to see what the function expects and returns. 
- use `lead(E,1)` to address the the row `n+1`
- make sure you're clear in what unit you are measuring speed. Meters per second is a SI base unit, but might be unhandy for the speeds travelled by wild boar. Perhaps make two speed columns, one in meters per second and one in km per hour?

<!-- Todo laup: ich denke km pro stunde macht wenig sinn. bleiben wir einfach bei m/s? -->

```{r}
## Task 3 ####################

library(CMAtools)

wildschwein_BE <- wildschwein_BE %>%
  group_by(TierID,samplingInt) %>%
  mutate(
    steplength = euclid(lead(E, 1),lead(N, 1),E,N),
    speed = steplength/timelag
  )



```




### Task 4

@laube2011 analyse animal movement across different scales (see below).

![@laube2011: *Black points are used in calculation of movement parameters (e.g. speed) at a given termporal scale.*](02_Images/laube_2011_2.jpg)


We will do the same for our data and will be working on a *subset* of our dataset. We will only need trajectories with a sampling interval of around 60 seconds ($$\pm$$20 seconds). Filter your data accordingly and save it to a new variable (we will use `wildschwein_BE_1`). From this subset, take the first 100 positions for the following task. 


#### Filter
If you like to stick to the `tidyverse` approach, you can use `slice()` to subset the dataset by row number. Slice takes an integer vector. Eg: `slice(dataset, 1:10)`, returns the first 10 rows of a dataset, `slice(dataset, c(1,5,10))` returns the 1^st^, 5^th^ and 10^th^ value of a dataset.

```{r}
wildschwein_BE_1 <- wildschwein_BE %>%
  filter(samplingInt == "40-80") %>%
  slice(2:100)
```

#### Resample 
Now manually reduce the granularity of our sampling interval by selecting samples every 3^rd^, 6^th^ and 9^th^ minute. 

- You can use `slice()` again for this task by providing an integer vector (with `seq()`) in the desired frequency
- Save each resampled dataset in a new variable. We will use (`wildschwein_BE_3`, `wildschwein_BE_6` and `wildschwein_BE_9`)


```{r}
wildschwein_BE_3 <- wildschwein_BE_1 %>%
  slice(seq(1,nrow(.),3)) # the dot (".") represents the piped dataset

wildschwein_BE_6 <- wildschwein_BE_1 %>%
  slice(seq(1,nrow(.),6))


wildschwein_BE_9 <- wildschwein_BE_1 %>%
  slice(seq(1,nrow(.),9))
```

#### Update derived parameters

`timelag`, `steplength` and `speed` now have to be recalculated on the basis of the resampled data. Do so as we illustrated in the Chapter *Demo*. 


```{r}
wildschwein_BE_3 <- wildschwein_BE_3 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = euclid(lead(E, 1),lead(N, 1),E,N),
    speed = steplength/timelag
  )

wildschwein_BE_6 <- wildschwein_BE_6 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = euclid(lead(E, 1),lead(N, 1),E,N),
    speed = steplength/timelag
  )


wildschwein_BE_9 <- wildschwein_BE_9 %>%
  mutate(
    timelag = as.numeric(difftime(lead(DatetimeUTC),DatetimeUTC,units = "secs")),
    steplength = euclid(lead(E, 1),lead(N, 1),E,N),
    speed = steplength/timelag
  )

```


#### Visualize 
Compare the speeds in a line plot and viualize the trajectories in a map (see examples below). Interpret the line plot, what do the different lines for the different temporal granularities tell you?

We've stored our location data in three different form in our dataset. Once as a `geometry`, once as `E`/`N` and once as `lat`/`long`. In our view, it is most practical to use the `E`/`N` (integer) columns of our data to map them in this task

- `geom_sf()` does not plot lines, just points
- Therefore, use `geom_path()` *and* `geom_point()` rather than `geom_sf()` within `ggplot`
- In contrast to `geom_sf()`, you have to explicitly specify  the `x`/`y` columns (in our case `E`/`N`) with `geom_path()`/`geom_point()`
- `geom_line()` does not work when mapping trajectory data, since it connects the observations *in order of the variable on the x axis*. `geom_path()` connects the observations in the order in which they appear in the data


```{r, echo = F, include = T,eval = T}



ggplot() +
  geom_point(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = wildschwein_BE_3, aes(E,N, colour = "3 minutes")) +
  geom_path(data = wildschwein_BE_3, aes(E,N, colour = "3 minutes")) +
  labs(color="Trajecotry", title = "Compare original with 3 minutes-resampled data")  +
  theme_minimal()

ggplot() +
  geom_point(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = wildschwein_BE_6, aes(E,N, colour = "6 minutes")) +
  geom_path(data = wildschwein_BE_6, aes(E,N, colour = "6 minutes")) +
  labs(color="Trajecotry", title = "Compare original with 6 minutes-resampled data") +
  theme_minimal()

ggplot() +
  geom_point(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_path(data = wildschwein_BE_1, aes(E,N, colour = "1 minute"), alpha = 0.2) +
  geom_point(data = wildschwein_BE_9, aes(E,N, colour = "9 minutes")) +
  geom_path(data = wildschwein_BE_9, aes(E,N, colour = "9 minutes"))+
  labs(color="Trajecotry", title = "Compare original with 9 minutes-resampled data") +
  theme_minimal()


ggplot() +
  geom_line(data = wildschwein_BE_1, aes(DatetimeUTC,speed, colour = "1 minute")) +
  geom_line(data = wildschwein_BE_3, aes(DatetimeUTC,speed, colour = "3 minutes")) +
  geom_line(data = wildschwein_BE_6, aes(DatetimeUTC,speed, colour = "6 minutes")) +
  geom_line(data = wildschwein_BE_9, aes(DatetimeUTC,speed, colour = "9 minutes")) +
  labs(x = "Time",y = "Speed (m/s)", title = "Comparing derived speed at different sampling intervals") +
  theme_minimal()

``` 


 
 




### Task 5 (Optional): Deriving movement parameters II: Rolling window functions

<!-- Todo laup: passt dieser Titel noch?  -->

A different approach would be to *smoothen* the derived parameters using a [moving window function](https://docs.wavefront.com/images/5sec_moving_window.png). The `zoo` package offers a variate of moving window functions (`roll*`). Use `roll_mean()` to smooth the calculated speed. Familiarise yourself with this function by working on some dummy data, for example:

```{r}
## Task 5 (Optional) ####################
```


```{r, echo = T, eval = T, include= T}

library(zoo)

example <- rnorm(10)
rollmean(example,k = 3,fill = NA,align = "left")
rollmean(example,k = 4,fill = NA,align = "left")

```

Now run `rollmean`on the `speed` variable of your original data (`wildschwein_BE`). Visualize the output from your moving windows and compare different window sizes (`k = `). It will probabbly make sense to just visualize a subset of your data.


```{r}


wildschwein_BE <- wildschwein_BE %>%
  group_by(TierID,samplingInt) %>%
  mutate(
    speed3 = rollmean(speed,3,NA,align = "left"),
    speed6 = rollmean(speed,6,NA,align = "left"),
    speed9 = rollmean(speed,9,NA,align = "left")
  )

wildschwein_BE[1:30,] %>%
  gather(key,val,c(speed,speed3,speed6,speed9)) %>%
  ggplot(aes(DatetimeUTC,val,colour = key,group = key)) +
  geom_point() +
  geom_line() 
```







## Solutions (RCode)

```{r code=readLines('12_Week2/RFiles/W02_01_Exercise.R'), results='asis', echo = T, include=T, eval=F}
```
