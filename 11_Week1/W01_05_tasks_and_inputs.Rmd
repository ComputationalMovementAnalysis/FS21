## Tasks and inputs



### Task 1: Initialize project

Create a new *RStudio Project*. As recommended in @wickham2017, remove the option "*Restore .RData into workspace at startup*" and set the option "*save workspace to .RData on exit*" to "*Never*".

Create a new .R (or .Rmd) File and divide it into the sections necessary in a classical Data Science Workflow. In .R Files, "Sections" can be created within RStudio by adding Comments (`#`) with at least 4 trailing dashes, equal, or pound signs ( `-`, `=`,`#`). In .Rmd Files, their are created with leading pound signs (`#`).

Sections allow code folding (try clicking on the small triangle next to the line number) and facilitate navigation (try the shortcut: `Shift`+`Alt`+`J`). We recommend following sections:

- Loading environment / libraries
- Data import
- Data cleansing
- Data analysis and visualization


```{r, code =  mydecrypt("11_Week1/solutions/task_1.R",".passphrase")}

```



### Task 2: Import data

In section "data import", import the file `wildschwein_BE.csv`. Obtain this file from moodle. Assign correct data types as necessary and make sure the time zone is set correctly for the date/time column.

Note: 

- If your are using [a graphical tool](https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio) to import your code, make sure you save the corresponding code in your R Script. This is important in regard to the reproducibility of your script and will ensure that your workflow is documented without gaps. We'd rather recommend to move away from using graphical tools and focus on using code. 
- We recommend using one of the `tidyverse` functions from the `readr` package to import your data (they all begin with "`read_*`, note the underscore). These functions are less error prone than the base `R` functions (`read.*`). Specifically for the wild boar data, we recommend `read_delim()`.
- If you use `read_delim()` and receive warnings during import, have a look at these warnings by using the function `problems()`. Resolve these problems until import runs without warnings.
- For everyone working on the RStudio Server: You will first need to upload this data to the server using the "*upload*"-button in the "*Files*" tab.


```{r, code =  mydecrypt("11_Week1/solutions/task_2.R",".passphrase")}
```



### Task 3: Explore Data

We will use a range of different visualization tools (i.e. R-packages) in this course. Several packages techniques have emerged in recent years, each with their specific strengths and weaknesses. While `base::plot() `is quick and simple, it not very scalable with growing complexity. `ggplot2` offers solutions for most use cases and has an elegant, consistent syntax that is easy to get accustomed to. We will get to know other techniques later in the course.

Get an overview of your data by creating a first "map-like" plot of your data producing a simple scatter plot with `ggplot2`. 
Setting up a `ggplot` with our data is done using the command `ggplot(wildschwein_BE, aes(Long, Lat, colour = TierID))`. Creating a map is done via the basic scatter plot command `geom_point()`.
<!-- Use `coord_map()` to get a reasonable aspect ratio of `Lat` and `Long`. -->
Assigning every individual its own colour is done using the `ggplot` argument `colour =`.

Save your code in the appropriate section.


```{r code =  mydecrypt("11_Week1/solutions/task_3.R",".passphrase")}
```


### Input: Handling spatial data

Until now, we've stored our location data within data frames as Lat/Long columns. This works well for many tasks, but sometimes we need special *spatial* classes to handle our trajectories. We will get to know such cases in our next tasks, but first we need to convert our `data.frame` into a spatial object.

We will largely rely on `sf`when working with vector data in `R`. In order to transform our `data.frame` into an sf object, we need to use the function `st_as_sf()` while specifying the columns storing the coordinates and the coordinate reference system.

(At this point, we assume you know what a Coordinate Reference Systems is. Check out [this link](https://earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/) if this is not the case.)





```{r input_handlingSpatialData, echo = TRUE, include = TRUE, eval = TRUE}

library(sf)

wildschwein_BE_sf <- st_as_sf(wildschwein_BE, 
                              coords = c("Long", "Lat"), 
                              crs = 4326)

```

Notice how `st_as_sf` takes the EPSG code for the `crs =` argument. You can find a lot of useful information on Coordinate Reference Systems (including EPSG Codes , etc.) under (epsg.io)[http://epsg.io].  
Let's compare our original `data.frame` with this new `sf` object:

```{r,  echo = TRUE, include = TRUE, eval = TRUE, collapse=FALSE}
wildschwein_BE

wildschwein_BE_sf
```

As you can see, `st_as_sf()` has added some metadata to our dataframe (`geometry type`, `dimension`, `bbox`, `epsg` and `proj4string`) and replaced the columns `Lat` and `Long` with a column named `geometry`. Other than that, the new `sf` object is very similar to our original dataframe. In fact, `sf` objects *are* essentially `dataframes`, as you can verify with the function `is.data.frame()`:

```{r,  echo = TRUE, purl = FALSE}
is.data.frame(wildschwein_BE_sf)
```

All operations we know from handling `data.frames` can be used on the `sf` object. Try some out!
```{r,  echo = TRUE, purl = FALSE, eval = FALSE}
# subset rows
wildschwein_BE_sf[1:10,]
wildschwein_BE_sf[wildschwein_BE_sf$TierName == "Sabi",]

# subset colums
wildschwein_BE_sf[,2:3]
```

Instead of keeping the same data twice (once as a `data.frame`, and once as an `sf` object), we will overwrite the `data.frame` and continue working with the `sf` object from now on. This saves some memory space in `R` and avoids confusion. 

```{r,  echo = T, include = T, eval = T}
wildschwein_BE <- st_as_sf(wildschwein_BE, 
                          coords = c("Long", "Lat"), 
                          crs = 4326)

rm(wildschwein_BE_sf) 
# we can remove this sf object, since it just eats up our memory

```


### Task 4: Project data from WGS84

So what can we do with our new `sf` object that we couldn't before? One example is projecting the WGS84 (`Lat`/`Long`) coordinates into the new Swiss CRS `CH1903+ LV95`[^50]. Do this by using the function `st_transform`. By the way, do you notice a pattern here? The package `sf` names most functions for spatial operations with the prefix `st_*`, just as in PostGIS.

[^50]: As we've mentioned in the first Input, you can look up the EPSG codes under (epsg.io)[http://epsg.io]. For information specific to Switzerland, check the [swisstopo website](https://www.swisstopo.admin.ch/en/knowledge-facts/surveying-geodesy/reference-systems.html) 


```{r, code =  mydecrypt("11_Week1/solutions/task_4.R",".passphrase")}

```


Here's the resulting `sf` object from the operation:
```{r, echo = FALSE, eval = TRUE}
wildschwein_BE
```



### Input: Calculate Convex Hull

Transforming from one Coordinate Reference System to another was one operation where we needed an object with a spatial nature. In this way, we were able to use an off the shelf function to project the coordinates from one CRS to another. In our next example, we again rely on a spatial function: We want to calculate a [convex hull](https://en.wikipedia.org/wiki/Convex_hull) per Wild boar. And guess what the function for calculating a convex hull is called in `sf`? If you guessed `st_convex_hull()`, you were right! 

By default `st_convex_hull()` calculates the convex hull *per feature*, i.e. *per point* in our dataset. This of course makes little sense. In order to calculate the convex hull per animal, we need to convert our point- to multipoint-features where each feature contains all positions of one animal. This is achieved in two steps:

First: add a grouping variable to the `sf` object. Note the new grouping variable in the metadata of the `sf` object. Other than that, `group_by` has no effect on our `sf` object.



```{r input_calculateConvexHull, echo = T,include = T,eval = T}

wildschwein_BE_grouped <- group_by(wildschwein_BE,TierID)

wildschwein_BE_grouped

```


Second: use `summarise()` to "dissolve" all points into a mulipoint object. 

```{r, echo = T,include = T,eval = T}
wildschwein_BE_smry <- summarise(wildschwein_BE_grouped)

wildschwein_BE_smry

```


Now we can run `st_convex_hull` on the new `sf` object. 

```{r, echo = T,include = T,eval = T}
mcp <- st_convex_hull(wildschwein_BE_smry)

```


### Task 5: Ploting spatial objects

Using base plot to visualize `sf` objects is easy enough, just try the following code. 


```{r echo = T,include = T,eval = T}
plot(mcp)
```

But since we use `ggplot` extensively, try and plot the object `mcp` with `ggplot`. Hint: Use the layer `geom_sf()` to add an `sf` object.
Note: `ggplot` refuses to use our specified CRS, so we need to force this by specifying `datum = ` in `coord_sf()`. Try it out.

```{r, eval = (1:2), include = TRUE, fig.cap = "No Datum specified",code =  mydecrypt("11_Week1/solutions/task_5.R",".passphrase")}
```

```{r, eval = (4:7), include = TRUE, fig.cap = "'datum' set to '2056' in coord_sf", code =  mydecrypt("11_Week1/solutions/task_5.R",".passphrase")}
```



### Input: Importing raster data

In the next task, we would like to add a background map to our `mcp` object. To do this, we have to the raster data into `R` first. For this, we use the package `terra` with the function `rast``.


```{r echo = TRUE,include = T}

library(terra)

pk100_BE <- terra::rast("00_Rawdata/pk100_BE_2056.tif")

pk100_BE
```


`pk100_BE_2056.tif` is a three layered geotiff File. The above console output shows some metadata including the resolution, extent and the names of our layers (`pk100_BE_2056.1`, `pk100_BE_2056.2`etc). For some reason, `rast` imported a fourth layer (`pk1_4 `). `plot()` shows that the fourth layer is empty. We will remove this layer using `subset()`. 

```{r, echo = T,include = T,eval = T}

plot(pk100_BE)

pk100_BE <- subset(pk100_BE,1:3)

plot(pk100_BE)

```



### Task 6: Adding a background map

There are multiple ways to add a background map in `ggplot`, many require additional packages. This is a good opportunity to get to know a completely different package for creating maps: `tmap` ("thematic map"). This package was developed with a syntax very similar to `ggplot2`, which makes it easy to learn.


```{r task6, echo = T,include = T,eval = T}
library(tmap)

tm_shape(pk100_BE) + 
  tm_rgb() 

```

As you can see, plotting layers in `tmap` is combined with the `+` sign, just as in `ggplot2`. In `tmap` however, each layer consists of two objects: a `tm_shape()` in which the data is called, and a `tm_*` object in which we define how the data is visualized (`tm_rgb()` states that it is plotted as an RGB Raster Layer). Add the object `mcp` to the plot in this manner. Read [the vignette](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html) if you are having trouble.

```{r, include = TRUE, fig.cap = "'datum' set to '2056' in coord_sf", code =  mydecrypt("11_Week1/solutions/task_6.R",".passphrase")}
```



### Task 7: Create an interactive map

Rerun the `tmap()...` command from the previous task, but switch the plotting mode to "view"" (`tmap_mode("view")`) beforehand. Omit the raster layer (`pk100_BE`), you won't be needing it.


```{r task7, echo = F,include = T,eval = FALSE}

tmap_mode("view")

tm_shape(mcp) +
  tm_polygons(col = "TierID",alpha = 0.4,border.col = "red") +
  tm_legend(bg.color = "white")
```
